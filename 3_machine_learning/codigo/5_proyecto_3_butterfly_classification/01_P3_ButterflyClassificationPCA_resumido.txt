{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BrajanNieto/Tareas_Programacion101_BrajanNieto/blob/main/01_P3_ButterflyClassificationPCA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " # Proyecto de clasificación 'Butterfly Image Classification with PyTorch neural networks'\n",
        " ----\n",
        "  \n",
        "  University : UTEC \\\\\n",
        "  Course       : Machine Learning \\\\\n",
        "  Professor    : Cristian López Del Alamo \\\\\n",
        "  Topic        : SVM \\\\\n",
        "  Deadline      : 18-08-2025\n",
        "   \n",
        "\n",
        " ----\n",
        "\n",
        "Write the names and surnames of the members and the percentage of participation of each one in the development of the practice:\n",
        " - Integrante 1: Lopez Medina Sebastian 100%\n",
        " - Integrante 2: Nieto Espinoza Brajan Esteban 100%\n",
        " - Integrante 3: Tapia Chasquibol Mateo 100%\n",
        "\n",
        " ----\n",
        " The objective of this project is to classify butterflies ."
      ],
      "metadata": {
        "id": "WrEdLIAuVClr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# 0. Insttalaciones\n",
        "# ============================================\n",
        "%pip -q install kagglehub scikit-learn pandas matplotlib seaborn pillow"
      ],
      "metadata": {
        "id": "rFi6SCfNezrJ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# 1. Librerías\n",
        "# ============================================\n",
        "\n",
        "# --- librerías estándar ---\n",
        "import os, glob, math, random, time, itertools\n",
        "from pathlib import Path\n",
        "from typing import List, Tuple, Dict\n",
        "from itertools import product\n",
        "from typing import Optional\n",
        "# ------------- librerías comunes ----\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from PIL import Image as PILImage\n",
        "from IPython.display import Image as IPyImage, display\n",
        "\n",
        "# --- PyTorch ----- torchvision ---\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "\n",
        "# --- Scikit-learn ---\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score,\n",
        "    f1_score, confusion_matrix, classification_report\n",
        ")\n",
        "\n",
        "# --- Kaggle (descarga de datos) ---\n",
        "import kagglehub\n",
        "\n",
        "\n",
        "# --- Info de paquetes ---\n",
        "print(\"PyTorch:\", torch.__version__)\n",
        "print(\"CUDA disponible:\", torch.cuda.is_available())\n",
        "print(\"NumPy:\", np.__version__)\n",
        "print(\"Pandas:\", pd.__version__)\n",
        "print(\"Matplotlib:\", plt.matplotlib.__version__)\n",
        "print(\"Seaborn:\", sns.__version__)\n"
      ],
      "metadata": {
        "id": "8U6Gyn-teupR",
        "outputId": "435e63fd-76fe-486e-9581-7aa97b79796c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch: 2.8.0+cu126\n",
            "CUDA disponible: False\n",
            "NumPy: 2.0.2\n",
            "Pandas: 2.2.2\n",
            "Matplotlib: 3.10.0\n",
            "Seaborn: 0.13.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================================\n",
        "# 2. Carga de datos, reproducibilidad, plotar imagenes\n",
        "# ========================================================\n",
        "# Descargar\n",
        "path = kagglehub.dataset_download(\"veeralakrishna/butterfly-dataset\")\n",
        "print(\"Descargado en:\", path)\n",
        "DATA_ROOT = Path(path) / \"leedsbutterfly\"\n",
        "print(\"DATA_ROOT:\", DATA_ROOT)\n",
        "# ver estructura\n",
        "!find \"$DATA_ROOT\" -maxdepth 2 -type d | sed 's|^|DIR: |'\n",
        "\n",
        "# -------------------------\n",
        "# Reproducibilidad\n",
        "# -------------------------\n",
        "def set_seed(seed: int = 42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False"
      ],
      "metadata": {
        "id": "Fbfejg3zNz9c",
        "outputId": "5b0228d2-fc3e-413a-da9f-b50c0fe523a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Descargado en: /kaggle/input/butterfly-dataset\n",
            "DATA_ROOT: /kaggle/input/butterfly-dataset/leedsbutterfly\n",
            "DIR: /kaggle/input/butterfly-dataset/leedsbutterfly\n",
            "DIR: /kaggle/input/butterfly-dataset/leedsbutterfly/images\n",
            "DIR: /kaggle/input/butterfly-dataset/leedsbutterfly/segmentations\n",
            "DIR: /kaggle/input/butterfly-dataset/leedsbutterfly/descriptions\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================================\n",
        "# 3. Dataset y transforms\n",
        "# ========================================================\n",
        "\n",
        "def list_png_labels(root: Path) -> Tuple[List[Tuple[str, int]], List[str]]:\n",
        "    paths = sorted([p for p in Path(root).iterdir() if p.is_file() and p.suffix.lower() == \".png\"])\n",
        "    prefixes = sorted({p.name[:3] for p in paths})\n",
        "    prefix_to_idx = {pref: i for i, pref in enumerate(prefixes)}\n",
        "    samples = [(str(p), prefix_to_idx[p.name[:3]]) for p in paths]\n",
        "    return samples, prefixes\n",
        "\n",
        "class FileListDataset(Dataset):\n",
        "    \"\"\"Dataset simple para (ruta, etiqueta) en carpeta plana.\"\"\"\n",
        "    def __init__(self, items: List[Tuple[str, int]], transform=None):\n",
        "        self.items = items\n",
        "        self.transform = transform\n",
        "    def __len__(self): return len(self.items)\n",
        "    def __getitem__(self, idx):\n",
        "        path, label = self.items[idx]\n",
        "        with PILImage.open(path) as img:\n",
        "            img = img.convert(\"RGB\")\n",
        "            if self.transform:\n",
        "                img = self.transform(img)\n",
        "        return img, label\n",
        "\n",
        "def build_transforms(img_size: int = 64,\n",
        "                     normalize: bool = True,\n",
        "                     augment: bool = True,\n",
        "                     for_mlp: bool = False):\n",
        "    norm = transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
        "                               std=(0.229, 0.224, 0.225)) if normalize else transforms.Lambda(lambda x: x)\n",
        "    aug = [transforms.RandomHorizontalFlip(p=0.5),\n",
        "           transforms.RandomRotation(degrees=10)] if augment else []\n",
        "    common = [transforms.Resize((img_size, img_size)), transforms.ToTensor(), norm]\n",
        "    if for_mlp:\n",
        "        common.append(transforms.Lambda(lambda t: t.view(-1)))  # aplanar a vector\n",
        "    train_tf = transforms.Compose(aug + common)\n",
        "    eval_tf  = transforms.Compose(common)\n",
        "    return train_tf, eval_tf, eval_tf\n",
        "\n",
        "# -------------------------\n",
        "# Prueba original vs transformada\n",
        "# -------------------------\n",
        "p = DATA_ROOT / \"images\" / \"0030060.png\"\n",
        "orig = PILImage.open(p).convert(\"RGB\")\n",
        "x = build_transforms(img_size=128, normalize=False, augment=True, for_mlp=False)[0](orig)\n",
        "plt.figure(figsize=(6,3))\n",
        "plt.subplot(1,2,1); plt.axis(\"off\"); plt.imshow(orig.resize((128,128)))\n",
        "plt.subplot(1,2,2); plt.axis(\"off\"); plt.imshow(x.permute(1,2,0).numpy())\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "fluY7mPanthD",
        "outputId": "30fc0961-4f19-4206-d461-bf4ef2d4a42b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x300 with 2 Axes>"
            ],
            "image/png": "[IMAGEN OMITIDA POR SU LONGITUD]"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================================\n",
        "# 4. Modelos: MLP y CNN\n",
        "# ========================================================\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_dim: int, hidden_sizes: List[int],\n",
        "                 num_classes: int, activation: str = \"relu\",\n",
        "                 dropout: float = 0.0):\n",
        "        super().__init__()\n",
        "        act = {\"relu\": nn.ReLU, \"tanh\": nn.Tanh, \"sigmoid\": nn.Sigmoid}\n",
        "        if activation not in act: raise ValueError(f\"Unsupported activation: {activation}\")\n",
        "        Act = act[activation]\n",
        "        layers: List[nn.Module] = []\n",
        "        prev = input_dim\n",
        "        for h in hidden_sizes:\n",
        "            layers.extend([nn.Linear(prev, h), Act()])\n",
        "            if dropout > 0: layers.append(nn.Dropout(dropout))\n",
        "            prev = h\n",
        "        layers.append(nn.Linear(prev, num_classes))\n",
        "        self.net = nn.Sequential(*layers)\n",
        "    def forward(self, x): return self.net(x)\n",
        "\n",
        "class SimpleCNN(nn.Module):\n",
        "    \"\"\"Asume img_size=64 → tras dos MaxPool2d(2) queda 16x16.\"\"\"\n",
        "    def __init__(self, num_classes: int, in_channels: int = 3):\n",
        "        super().__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, 32, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
        "            nn.Conv2d(32, 64, 3, padding=1),        nn.ReLU(), nn.MaxPool2d(2),\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(64 * 16 * 16, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, num_classes),\n",
        "        )\n",
        "    def forward(self, x): return self.classifier(self.features(x))\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# Prueba mínima (misma imagen → shapes de logits)\n",
        "# -------------------------\n",
        "K = len(list_png_labels(DATA_ROOT / \"images\")[1])\n",
        "p = DATA_ROOT / \"images\" / \"0030060.png\"\n",
        "img = PILImage.open(p).convert(\"RGB\")\n",
        "# Vector para MLP\n",
        "x_vec_ = build_transforms(64, normalize=False, augment=False, for_mlp=True)[0](img)   # [3*64*64]\n",
        "print(\"x_vec shape:\", tuple(x_vec_.shape), \"| primeros 8:\", x_vec_[:8].tolist())\n",
        "# Tensor imagen para CNN\n",
        "x_img_ = build_transforms(64, normalize=False, augment=False, for_mlp=False)[0](img)  # [3,64,64]\n",
        "print(\"x_img shape:\", tuple(x_img_.shape),\n",
        "      \"| patch[ :,0:2,0:2 ]:\\n\", x_img_[:, :2, :2],\n",
        "      \"\\nmin/max/mean:\", float(x_img_.min()), float(x_img_.max()), float(x_img_.mean()))\n",
        "\n",
        "x_vec = x_vec_.unsqueeze(0)  # [1, 3*64*64]\n",
        "x_img = x_img_.unsqueeze(0)  # [1, 3, 64, 64]\n",
        "\n",
        "# ---------- Modelos ----------\n",
        "mlp = MLP(input_dim=x_vec.shape[1], hidden_sizes=[128, 64], num_classes=K)\n",
        "cnn = SimpleCNN(num_classes=K)\n",
        "mlp.eval(); cnn.eval()\n",
        "\n",
        "# ---------- Hooks ----------\n",
        "hooks = []\n",
        "def mk_hook(tag):\n",
        "    def _hook(m, inp, out):\n",
        "        t = out[0] if isinstance(out, (list, tuple)) else out\n",
        "        print(f\"[{tag}] shape={tuple(t.shape)} | mean={float(t.mean()):.4f} std={float(t.std()):.4f}\")\n",
        "    return _hook\n",
        "for i, m in enumerate(mlp.net):\n",
        "    hooks.append(m.register_forward_hook(mk_hook(f\"MLP {i}:{m.__class__.__name__}\")))\n",
        "for i, m in enumerate(cnn.features):\n",
        "    hooks.append(m.register_forward_hook(mk_hook(f\"CNN-feat {i}:{m.__class__.__name__}\")))\n",
        "for i, m in enumerate(cnn.classifier):\n",
        "    hooks.append(m.register_forward_hook(mk_hook(f\"CNN-cls {i}:{m.__class__.__name__}\")))\n",
        "# --------------------\n",
        "with torch.no_grad():\n",
        "    print(\"\\n>>> Forward MLP\")\n",
        "    y_mlp = mlp(x_vec)   # [1,K]\n",
        "    print(\"MLP logits:\", tuple(y_mlp.shape), \":\", y_mlp[0, :min(10, K)].tolist())\n",
        "    print(\"\\n>>> Forward CNN\")\n",
        "    y_cnn = cnn(x_img)   # [1,K]\n",
        "    print(\"CNN logits:\", tuple(y_cnn.shape), \":\", y_cnn[0, :min(10, K)].tolist())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "biMAPIZBo9bu",
        "outputId": "ebcd26ee-b634-4ae9-c8de-11ae807e4eb5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_vec shape: (12288,) | primeros 8: [0.6274510025978088, 0.6274510025978088, 0.6117647290229797, 0.6000000238418579, 0.6000000238418579, 0.6000000238418579, 0.6000000238418579, 0.5882353186607361]\n",
            "x_img shape: (3, 64, 64) | patch[ :,0:2,0:2 ]:\n",
            " tensor([[[0.6275, 0.6275],\n",
            "         [0.6275, 0.6275]],\n",
            "\n",
            "        [[0.9412, 0.9412],\n",
            "         [0.9412, 0.9412]],\n",
            "\n",
            "        [[0.9373, 0.9373],\n",
            "         [0.9373, 0.9373]]]) \n",
            "min/max/mean: 0.0 1.0 0.5521376132965088\n",
            "\n",
            ">>> Forward MLP\n",
            "[MLP 0:Linear] shape=(1, 128) | mean=-0.0093 std=0.3852\n",
            "[MLP 1:ReLU] shape=(1, 128) | mean=0.1443 std=0.2126\n",
            "[MLP 2:Linear] shape=(1, 64) | mean=-0.0000 std=0.1780\n",
            "[MLP 3:ReLU] shape=(1, 64) | mean=0.0739 std=0.0976\n",
            "[MLP 4:Linear] shape=(1, 10) | mean=-0.0266 std=0.0706\n",
            "MLP logits: (1, 10) : [0.06866984814405441, 0.06328374147415161, 0.0060164183378219604, -0.022964568808674812, -0.12984594702720642, -0.04269465059041977, -0.04991923272609711, 0.0001535322517156601, -0.013224989175796509, -0.14587408304214478]\n",
            "\n",
            ">>> Forward CNN\n",
            "[CNN-feat 0:Conv2d] shape=(1, 32, 64, 64) | mean=-0.0338 std=0.3721\n",
            "[CNN-feat 1:ReLU] shape=(1, 32, 64, 64) | mean=0.1168 std=0.1755\n",
            "[CNN-feat 2:MaxPool2d] shape=(1, 32, 32, 32) | mean=0.1377 std=0.1882\n",
            "[CNN-feat 3:Conv2d] shape=(1, 64, 32, 32) | mean=0.0008 std=0.1480\n",
            "[CNN-feat 4:ReLU] shape=(1, 64, 32, 32) | mean=0.0574 std=0.0853\n",
            "[CNN-feat 5:MaxPool2d] shape=(1, 64, 16, 16) | mean=0.0739 std=0.0945\n",
            "[CNN-cls 0:Flatten] shape=(1, 16384) | mean=0.0739 std=0.0945\n",
            "[CNN-cls 1:Linear] shape=(1, 128) | mean=-0.0068 std=0.0659\n",
            "[CNN-cls 2:ReLU] shape=(1, 128) | mean=0.0238 std=0.0348\n",
            "[CNN-cls 3:Linear] shape=(1, 10) | mean=-0.0147 std=0.0673\n",
            "CNN logits: (1, 10) : [0.11004872620105743, -0.10899947583675385, -0.10014984756708145, -0.048905402421951294, -0.04805829003453255, 0.001415058970451355, 0.01520707830786705, -0.03785111382603645, 0.03750407695770264, 0.032997287809848785]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================================\n",
        "# 4. Entrenamiento / evaluación / métricas\n",
        "# ========================================================\n",
        "\n",
        "# -------------------------\n",
        "# compute_metrics — Métricas agregadas (accuracy, macro/weighted F1)\n",
        "# -------------------------\n",
        "def compute_metrics(y_true, y_pred) -> Dict[str, float]:\n",
        "    \"\"\"Devuelve métricas agregadas: accuracy, macro-precision/recall/F1, weighted-F1.\"\"\"\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    prec_m = precision_score(y_true, y_pred, average='macro', zero_division=0)\n",
        "    rec_m  = recall_score(y_true, y_pred, average='macro', zero_division=0)\n",
        "    f1_m   = f1_score(y_true, y_pred, average='macro', zero_division=0)\n",
        "    f1_w   = f1_score(y_true, y_pred, average='weighted', zero_division=0)\n",
        "    return {\"accuracy\": acc, \"precision_macro\": prec_m, \"recall_macro\": rec_m,\n",
        "            \"f1_macro\": f1_m, \"f1_weighted\": f1_w}\n",
        "\n",
        "# -------------------------\n",
        "# train_one_epoch — Entrenamiento de una época (loss y acc)\n",
        "# -------------------------\n",
        "def train_one_epoch(model, loader, criterion, optimizer, device):\n",
        "    \"\"\"Entrena 1 época y devuelve (loss_promedio, accuracy_promedio).\"\"\"\n",
        "    model.train()\n",
        "    total, correct, loss_sum = 0, 0, 0.0\n",
        "    for xb, yb in loader:\n",
        "        xb, yb = xb.to(device), yb.to(device)\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        logits = model(xb)\n",
        "        loss = criterion(logits, yb)\n",
        "        loss.backward(); optimizer.step()\n",
        "        loss_sum += loss.item() * xb.size(0)\n",
        "        correct += (logits.argmax(1) == yb).sum().item()\n",
        "        total += xb.size(0)\n",
        "    return loss_sum / total, correct / total\n",
        "\n",
        "# -------------------------\n",
        "# evaluate — Evaluación (loss, acc y vectores y_true/y_pred)\n",
        "# -------------------------\n",
        "@torch.no_grad()\n",
        "def evaluate(model, loader, criterion, device):\n",
        "    \"\"\"Evalúa y devuelve (loss_prom, acc_prom, y_true, y_pred).\"\"\"\n",
        "    model.eval()\n",
        "    total, correct, loss_sum = 0, 0, 0.0\n",
        "    y_true, y_pred = [], []\n",
        "    for xb, yb in loader:\n",
        "        xb, yb = xb.to(device), yb.to(device)\n",
        "        logits = model(xb)\n",
        "        loss = criterion(logits, yb)\n",
        "        loss_sum += loss.item() * xb.size(0)\n",
        "        preds = logits.argmax(1)\n",
        "        correct += (preds == yb).sum().item()\n",
        "        total += xb.size(0)\n",
        "        y_true.extend(yb.tolist()); y_pred.extend(preds.tolist())\n",
        "    return loss_sum / total, correct / total, np.array(y_true), np.array(y_pred)\n",
        "\n",
        "# -------------------------\n",
        "# plot_curves — Guardar curvas de pérdida y accuracy\n",
        "# -------------------------\n",
        "def plot_curves(history: Dict[str, List[float]], title: str, out_png: Path):\n",
        "    \"\"\"Guarda dos PNG: curvas de pérdida y de accuracy por época.\"\"\"\n",
        "    base = Path(out_png); base.parent.mkdir(parents=True, exist_ok=True)\n",
        "    loss_path = base.with_name(f\"{base.stem}_loss.png\")\n",
        "    acc_path  = base.with_name(f\"{base.stem}_acc.png\")\n",
        "    epochs = range(1, len(history[\"train_loss\"]) + 1)\n",
        "\n",
        "    plt.figure(figsize=(6,4))\n",
        "    plt.plot(epochs, history[\"train_loss\"], label=\"Train Loss\")\n",
        "    plt.plot(epochs, history[\"val_loss\"],   label=\"Val Loss\")\n",
        "    plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\"); plt.title(f\"{title} - Loss\")\n",
        "    plt.legend(); plt.tight_layout(); plt.savefig(loss_path, dpi=150); plt.close()\n",
        "\n",
        "    plt.figure(figsize=(6,4))\n",
        "    plt.plot(epochs, history[\"train_acc\"], label=\"Train Acc\")\n",
        "    plt.plot(epochs, history[\"val_acc\"],   label=\"Val Acc\")\n",
        "    plt.xlabel(\"Epoch\"); plt.ylabel(\"Accuracy\"); plt.title(f\"{title} - Accuracy\")\n",
        "    plt.legend(); plt.tight_layout(); plt.savefig(acc_path, dpi=150); plt.close()\n",
        "\n",
        "# -------------------------\n",
        "# save_confusion_matrix — (impresión) Matriz de confusión en tabla (sin gráfico)\n",
        "# -------------------------\n",
        "\n",
        "def print_confusion_matrix(y_true, y_pred, class_names, title: str, out_png: Optional[Path] = None):\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=list(range(len(class_names))))\n",
        "    df = pd.DataFrame(cm, index=[f\"true_{c}\" for c in class_names],\n",
        "                         columns=[f\"pred_{c}\" for c in class_names])\n",
        "    print(f\"\\n{title} — Matriz de confusión\")\n",
        "    print(df.to_string())\n",
        "    return cm, df"
      ],
      "metadata": {
        "id": "-z-io7RjvzyD"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================================\n",
        "# 5. Runner de entrenamiento /  (con PCA )\n",
        "# ========================================================\n",
        "def run_experiment(\n",
        "    data_root: Path, img_size: int, batch_size: int, epochs: int,\n",
        "    lr: float, optimizer_name: str, augment: bool, activation: str,\n",
        "    hidden_sizes: List[int], dropout: float, model_type: str,\n",
        "    num_workers: int, seed: int, device_str: str = None,\n",
        "    save_artifacts: bool = False,          # (igual que antes)\n",
        "    # --- NUEVO: flags para PCA en MLP ---\n",
        "    use_pca: bool = False,\n",
        "    pca_var: float = 0.90,\n",
        "    pca_whiten: bool = False\n",
        "):\n",
        "    \"\"\"\n",
        "    Si model_type=='mlp' y use_pca=True:\n",
        "      - Se vectoriza cada imagen (64x64x3 normalizada), se apila en matrices,\n",
        "      - Se ajusta PCA con n_components=pca_var (proporción de var. explicada),\n",
        "      - Se entrenan DataLoaders con TensorDataset de features PCA.\n",
        "    Nota: en el camino PCA se ignora 'augment' (PCA se ajusta sobre datos normalizados, no aumentados).\n",
        "    \"\"\"\n",
        "    from sklearn.decomposition import PCA\n",
        "\n",
        "    set_seed(seed)\n",
        "    device = torch.device(device_str) if device_str else torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    pin = (device.type == \"cuda\")\n",
        "    print(f\"[Device] {device} | CUDA avail={torch.cuda.is_available()}\")\n",
        "\n",
        "    # Datos (asumimos .../images)\n",
        "    root_images = Path(data_root) / \"images\"\n",
        "    samples, class_names = list_png_labels(root_images)\n",
        "    num_classes = len(class_names)\n",
        "    print(f\"[Data] imgs={len(samples)} | clases={num_classes} | img_size={img_size} | augment={augment} | use_pca={use_pca}\")\n",
        "\n",
        "    # Split 80/10/10\n",
        "    paths  = [p for p, y in samples]\n",
        "    labels = [y for _, y in samples]\n",
        "    tr_paths, tmp_paths, tr_y, tmp_y = train_test_split(paths, labels, test_size=0.2, random_state=seed, stratify=labels)\n",
        "    va_paths, te_paths, va_y, te_y   = train_test_split(tmp_paths, tmp_y, test_size=0.5, random_state=seed, stratify=tmp_y)\n",
        "    print(f\"[Split] train={len(tr_paths)} | val={len(va_paths)} | test={len(te_paths)} | batch_size={batch_size}\")\n",
        "\n",
        "    # ===========================\n",
        "    # Transforms / Datasets\n",
        "    # ===========================\n",
        "    if model_type.lower() == \"mlp\":\n",
        "        if use_pca:\n",
        "            # --- Vectorización fija + normalización (sin augment) ---\n",
        "            to_vec = transforms.Compose([\n",
        "                transforms.Resize((img_size, img_size)),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize(mean=(0.485,0.456,0.406), std=(0.229,0.224,0.225)),\n",
        "                transforms.Lambda(lambda t: t.view(-1))\n",
        "            ])\n",
        "            def load_matrix(pths):\n",
        "                X = np.stack([to_vec(PILImage.open(p).convert(\"RGB\")).numpy() for p in pths], axis=0)\n",
        "                return X\n",
        "\n",
        "            Xtr = load_matrix(tr_paths); ytr = np.array(tr_y)\n",
        "            Xva = load_matrix(va_paths); yva = np.array(va_y)\n",
        "            Xte = load_matrix(te_paths); yte = np.array(te_y)\n",
        "\n",
        "            pca = PCA(n_components=pca_var, svd_solver=\"full\", whiten=pca_whiten, random_state=seed)\n",
        "            Xtr = pca.fit_transform(Xtr); Xva = pca.transform(Xva); Xte = pca.transform(Xte)\n",
        "\n",
        "            input_dim = Xtr.shape[1]\n",
        "            print(f\"[PCA] var_exp≈{pca.explained_variance_ratio_.sum():.4f} | dim: {3*img_size*img_size} → {input_dim} \"\n",
        "                  f\"| whiten={pca_whiten}\")\n",
        "\n",
        "            ds_tr = torch.utils.data.TensorDataset(torch.from_numpy(Xtr).float(), torch.from_numpy(ytr).long())\n",
        "            ds_va = torch.utils.data.TensorDataset(torch.from_numpy(Xva).float(), torch.from_numpy(yva).long())\n",
        "            ds_te = torch.utils.data.TensorDataset(torch.from_numpy(Xte).float(), torch.from_numpy(yte).long())\n",
        "\n",
        "            dl_tr = DataLoader(ds_tr, batch_size=batch_size, shuffle=True,  num_workers=num_workers, pin_memory=pin)\n",
        "            dl_va = DataLoader(ds_va, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=pin)\n",
        "            dl_te = DataLoader(ds_te, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=pin)\n",
        "\n",
        "        else:\n",
        "            # --- Camino original (sin PCA) ---\n",
        "            tf_tr, tf_va, tf_te = build_transforms(img_size, normalize=True, augment=augment, for_mlp=True)\n",
        "            input_dim = 3 * img_size * img_size\n",
        "            ds_tr = FileListDataset(list(zip(tr_paths, tr_y)), transform=tf_tr)\n",
        "            ds_va = FileListDataset(list(zip(va_paths, va_y)), transform=tf_va)\n",
        "            ds_te = FileListDataset(list(zip(te_paths, te_y)), transform=tf_te)\n",
        "            dl_tr = DataLoader(ds_tr, batch_size=batch_size, shuffle=True,  num_workers=num_workers, pin_memory=pin)\n",
        "            dl_va = DataLoader(ds_va, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=pin)\n",
        "            dl_te = DataLoader(ds_te, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=pin)\n",
        "\n",
        "    else:\n",
        "        # CNN: flujo original\n",
        "        tf_tr, tf_va, tf_te = build_transforms(img_size, normalize=True, augment=augment, for_mlp=False)\n",
        "        ds_tr = FileListDataset(list(zip(tr_paths, tr_y)), transform=tf_tr)\n",
        "        ds_va = FileListDataset(list(zip(va_paths, va_y)), transform=tf_va)\n",
        "        ds_te = FileListDataset(list(zip(te_paths, te_y)), transform=tf_te)\n",
        "        dl_tr = DataLoader(ds_tr, batch_size=batch_size, shuffle=True,  num_workers=num_workers, pin_memory=pin)\n",
        "        dl_va = DataLoader(ds_va, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=pin)\n",
        "        dl_te = DataLoader(ds_te, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=pin)\n",
        "\n",
        "    # ===========================\n",
        "    # Modelo\n",
        "    # ===========================\n",
        "    if model_type.lower() == \"mlp\":\n",
        "        model = MLP(\n",
        "            input_dim=input_dim,\n",
        "            hidden_sizes=hidden_sizes if hidden_sizes else [1024, 512],\n",
        "            num_classes=num_classes,\n",
        "            activation=activation,\n",
        "            dropout=dropout\n",
        "        )\n",
        "        pca_tag = (f\"_PCA{int(round(pca_var*100))}\" + (\"W\" if pca_whiten else \"\")) if use_pca else \"\"\n",
        "        title = f\"MLP_{activation}_hs{hidden_sizes if hidden_sizes else [1024,512]}_do{dropout}{pca_tag}\"\n",
        "        act_desc = activation\n",
        "    else:\n",
        "        model = SimpleCNN(num_classes=num_classes)\n",
        "        title = \"SimpleCNN\"\n",
        "        act_desc = \"ReLU(fija)\"\n",
        "    model = model.to(device)\n",
        "\n",
        "    # ===========================\n",
        "    # Loss & Optimizer\n",
        "    # ===========================\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    opt_name = optimizer_name.lower()\n",
        "    if opt_name == \"adam\":\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "        opt_desc = f\"Adam(lr={lr})\"\n",
        "    elif opt_name == \"sgd\":\n",
        "        optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
        "        opt_desc = f\"SGD(lr={lr}, momentum=0.9)\"\n",
        "    else:\n",
        "        raise ValueError(\"optimizer must be 'adam' or 'sgd'\")\n",
        "    print(f\"[Model] {title} | optimizer={opt_desc} | dropout={dropout} | activation={act_desc}\")\n",
        "\n",
        "    # ===========================\n",
        "    # Entrenamiento\n",
        "    # ===========================\n",
        "    history = {\"train_loss\": [], \"val_loss\": [], \"train_acc\": [], \"val_acc\": []}\n",
        "    best_val_f1, best_state = -1.0, None\n",
        "    t0 = time.perf_counter()\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        tr_loss, tr_acc = train_one_epoch(model, dl_tr, criterion, optimizer, device)\n",
        "        va_loss, va_acc, y_val, p_val = evaluate(model, dl_va, criterion, device)\n",
        "        f1_m = f1_score(y_val, p_val, average='macro', zero_division=0)\n",
        "\n",
        "        history[\"train_loss\"].append(tr_loss); history[\"val_loss\"].append(va_loss)\n",
        "        history[\"train_acc\"].append(tr_acc);   history[\"val_acc\"].append(va_acc)\n",
        "\n",
        "        if f1_m > best_val_f1:\n",
        "            best_val_f1 = f1_m\n",
        "            best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
        "\n",
        "        print(f\"[{title}] Ep {epoch:02d}/{epochs} | Train loss {tr_loss:.4f} acc {tr_acc:.3f} | \"\n",
        "              f\"Val loss {va_loss:.4f} acc {va_acc:.3f} F1(macro) {f1_m:.3f}\")\n",
        "\n",
        "    elapsed = (time.perf_counter() - t0) / max(1, epochs)\n",
        "    print(f\"[Tiempo] ~{elapsed:.2f}s/epoch | best Val F1(macro)={best_val_f1:.3f}\")\n",
        "\n",
        "    # ===========================\n",
        "    # Test (mejor estado)\n",
        "    # ===========================\n",
        "    if best_state is not None:\n",
        "        model.load_state_dict(best_state)\n",
        "    _, _, y_test, p_test = evaluate(model, dl_te, criterion, device)\n",
        "    test_metrics = compute_metrics(y_test, p_test)\n",
        "    print(f\"[Test] acc={test_metrics['accuracy']:.3f} | F1(macro)={test_metrics['f1_macro']:.3f} | F1(weighted)={test_metrics['f1_weighted']:.3f}\")\n",
        "\n",
        "    # Matrices y reporte\n",
        "    print_confusion_matrix(y_test, p_test, class_names, f\"{title} - Confusion Matrix\")\n",
        "    print(\"\\n[Classification report]\")\n",
        "    print(classification_report(\n",
        "        y_test, p_test, labels=list(range(num_classes)),\n",
        "        target_names=class_names, digits=3, zero_division=0\n",
        "    ))\n",
        "\n",
        "    # ===========================\n",
        "    # Guardados opcionales\n",
        "    # ===========================\n",
        "    if save_artifacts:\n",
        "        out_dir = Path(\"outputs\"); out_dir.mkdir(parents=True, exist_ok=True)\n",
        "        plot_curves(history, title, out_dir / f\"{title}.png\")\n",
        "\n",
        "        report_dict = classification_report(\n",
        "            y_test, p_test,\n",
        "            labels=list(range(num_classes)),\n",
        "            target_names=class_names,\n",
        "            output_dict=True, zero_division=0\n",
        "        )\n",
        "        pd.DataFrame(report_dict).to_csv(out_dir / f\"{title}_classification_report.csv\", index=True)\n",
        "\n",
        "        cm = confusion_matrix(y_test, p_test, labels=list(range(num_classes)))\n",
        "        df_cm = pd.DataFrame(cm,\n",
        "                              index=[f\"true_{c}\" for c in class_names],\n",
        "                              columns=[f\"pred_{c}\" for c in class_names])\n",
        "        df_cm.to_csv(out_dir / f\"{title}_confusion_matrix.csv\")\n",
        "\n",
        "        cm_norm = (cm / cm.sum(axis=1, keepdims=True)).round(6)\n",
        "        df_cm_norm = pd.DataFrame(cm_norm,\n",
        "                                  index=[f\"true_{c}\" for c in class_names],\n",
        "                                  columns=[f\"pred_{c}\" for c in class_names])\n",
        "        df_cm_norm.to_csv(out_dir / f\"{title}_confusion_matrix_norm.csv\")\n",
        "\n",
        "    return {\n",
        "        \"model_type\": model_type,\n",
        "        \"model\": title,\n",
        "        \"optimizer\": optimizer.__class__.__name__,\n",
        "        \"lr\": lr,\n",
        "        \"dropout\": dropout if model_type.lower()==\"mlp\" else None,\n",
        "        \"activation\": activation if model_type.lower()==\"mlp\" else \"relu\",\n",
        "        \"img_size\": img_size,\n",
        "        \"batch_size\": batch_size,\n",
        "        \"epochs\": epochs,\n",
        "        \"time_per_epoch_sec\": elapsed,\n",
        "        \"n_train\": len(tr_paths), \"n_val\": len(va_paths), \"n_test\": len(te_paths),\n",
        "        \"accuracy\": test_metrics[\"accuracy\"],\n",
        "        \"precision_macro\": test_metrics[\"precision_macro\"],\n",
        "        \"recall_macro\": test_metrics[\"recall_macro\"],\n",
        "        \"f1_macro\": test_metrics[\"f1_macro\"],\n",
        "        \"f1_weighted\": test_metrics[\"f1_weighted\"],\n",
        "        \"classes\": class_names,\n",
        "        # --- NUEVO: registro de PCA ---\n",
        "        \"use_pca\": use_pca if model_type.lower()==\"mlp\" else False,\n",
        "        \"pca_var\": pca_var if (model_type.lower()==\"mlp\" and use_pca) else None,\n",
        "        \"pca_whiten\": pca_whiten if (model_type.lower()==\"mlp\" and use_pca) else None,\n",
        "    }\n"
      ],
      "metadata": {
        "id": "7oiQyT7Kcc1g"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================================\n",
        "# 6. Grid search (inteligente) + resumen de resultados\n",
        "# ========================================================\n",
        "from itertools import product\n",
        "import time, numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# ----- Espacio de búsqueda MLP (PCA=True, más amplio e inteligente) -----\n",
        "mlp_space = {\n",
        "    \"model_type\":     [\"mlp\"],\n",
        "    \"img_size\":       [64],\n",
        "    \"batch_size\":     [128, 8, 16],             # añadimos 64 para estabilidad con LR altos\n",
        "    \"epochs\":         [30],\n",
        "    \"optimizer_name\": [\"adam\", \"sgd\"],\n",
        "    # rangos más amplios\n",
        "    \"lr_adam\":        [5e-3, 3e-4, 1e-4],\n",
        "    \"lr_sgd\":         [1e-2, 1e-3],\n",
        "    \"augment\":        [True],                   # (ignorado cuando use_pca=True)\n",
        "    \"activation\":     [\"relu\", \"tanh\", \"sigmoid\"],\n",
        "    # más opciones, recordando que con PCA la entrada es más chica\n",
        "    \"hidden_sizes\":   [[512, 256], [256, 128], [1024, 512], [64, 32]],\n",
        "    \"dropout\":        [0.5, 0.1, 0.3],          # la lógica inteligente filtrará según tamaño de red\n",
        "    # --- PCA fijo en True, y exploramos varianza/whiten ---\n",
        "    \"use_pca\":        [True],\n",
        "    \"pca_var\":        [0.95],\n",
        "    \"pca_whiten\":     [False, True],\n",
        "}\n",
        "\n",
        "# ----- Espacio de búsqueda CNN (igual que antes, sin PCA externo) -----\n",
        "cnn_space = {\n",
        "    \"model_type\":     [\"cnn\"],\n",
        "    \"img_size\":       [64],                     # SimpleCNN asume 64x64\n",
        "    \"batch_size\":     [32, 16],\n",
        "    \"epochs\":         [30],\n",
        "    \"optimizer_name\": [\"adam\", \"sgd\"],\n",
        "    \"lr_adam\":        [1e-3, 3e-4, 1e-2],       # considera quitar 1e-2 si ves inestabilidad\n",
        "    \"lr_sgd\":         [1e-2, 3e-3],\n",
        "    \"augment\":        [True, False],\n",
        "    \"activation\":     [\"relu\"],                 # ignorado en CNN actual\n",
        "    \"hidden_sizes\":   [[]],                     # ignorado\n",
        "    \"dropout\":        [0.0],                    # ignorado\n",
        "}\n",
        "\n",
        "# ----------------- Utilidades de heurística -----------------\n",
        "def _is_large(hs):   return hs in ([512, 256], [256, 128])\n",
        "def _is_small(hs):   return hs in ([96, 48], [64, 32])\n",
        "\n",
        "def _allowed_dropouts(hs, pca_var, pca_whiten):\n",
        "    # Redes grandes: más regularización\n",
        "    if _is_large(hs):\n",
        "        return [0.2, 0.4]\n",
        "    # Varianza muy baja (0.85) sin whiten → evitar 0.0 por posible sobreajuste\n",
        "    if (pca_var <= 0.85 + 1e-9) and (not pca_whiten):\n",
        "        return [0.2, 0.4]\n",
        "    # En el resto: 0.0 y 0.2 son razonables\n",
        "    return [0.0, 0.2]\n",
        "\n",
        "def _lr_candidates(opt, hs, act, bs, base_lrs_adam, base_lrs_sgd):\n",
        "    if opt == \"adam\":\n",
        "        lrs = list(base_lrs_adam)  # [1e-3, 5e-4, 3e-4, 1e-4]\n",
        "        # Tanh/Sigmoid saturan con LR grande → recortar\n",
        "        if act in (\"tanh\", \"sigmoid\"):\n",
        "            lrs = [lr for lr in lrs if lr <= 5e-4]\n",
        "        # Redes muy grandes con Adam: evitar 1e-3 si batch muy chico\n",
        "        if _is_large(hs) and bs == 16:\n",
        "            lrs = [lr for lr in lrs if lr <= 5e-4]\n",
        "        return lrs\n",
        "    else:  # sgd\n",
        "        lrs = list(base_lrs_sgd)   # [1e-2, 3e-3, 1e-3]\n",
        "        # Solo ReLU con LR altos de SGD\n",
        "        if act in (\"tanh\", \"sigmoid\"):\n",
        "            lrs = [lr for lr in lrs if lr <= 3e-3]\n",
        "        # Batch 16 con SGD no va bien con 1e-2\n",
        "        if bs == 16:\n",
        "            lrs = [lr for lr in lrs if lr < 1e-2]\n",
        "        # Redes grandes con SGD: evita 1e-2\n",
        "        if _is_large(hs):\n",
        "            lrs = [lr for lr in lrs if lr <= 3e-3]\n",
        "        return lrs\n",
        "\n",
        "# ----------------- Generadores de combinaciones -----------------\n",
        "def iter_space_with_lrs(space):\n",
        "    \"\"\"Versión simple (para CNN) que solo inserta LR según optimizador.\"\"\"\n",
        "    keys_base = [k for k in space.keys() if k not in (\"lr_adam\", \"lr_sgd\")]\n",
        "    values_base = [space[k] for k in keys_base]\n",
        "    for vals in product(*values_base):\n",
        "        cfg = dict(zip(keys_base, vals))\n",
        "        lrs = space[\"lr_adam\"] if cfg[\"optimizer_name\"].lower() == \"adam\" else space[\"lr_sgd\"]\n",
        "        for lr in lrs:\n",
        "            yield {**cfg, \"lr\": lr}\n",
        "\n",
        "def iter_space_smart(space):\n",
        "    \"\"\"\n",
        "    Genera combinaciones 'inteligentes' para MLP+PCA aplicando reglas:\n",
        "    - Dropout según tamaño de red y configuración PCA.\n",
        "    - Recorte de LR según activación, tamaño de red y batch size.\n",
        "    - Evita combinaciones inestables/ineficientes.\n",
        "    \"\"\"\n",
        "    keys_base = [k for k in space.keys() if k not in (\"lr_adam\", \"lr_sgd\", \"dropout\")]\n",
        "    values_base = [space[k] for k in keys_base]\n",
        "    for vals in product(*values_base):\n",
        "        cfg = dict(zip(keys_base, vals))\n",
        "\n",
        "        # Alias\n",
        "        opt = cfg[\"optimizer_name\"].lower()\n",
        "        act = cfg[\"activation\"].lower()\n",
        "        hs  = cfg[\"hidden_sizes\"]\n",
        "        bs  = cfg[\"batch_size\"]\n",
        "        pv  = cfg[\"pca_var\"]\n",
        "        pw  = cfg[\"pca_whiten\"]\n",
        "\n",
        "        # Dropouts permitidos según heurística\n",
        "        dropouts = _allowed_dropouts(hs, pv, pw)\n",
        "\n",
        "        # LR candidatos según heurística\n",
        "        lrs = _lr_candidates(opt, hs, act, bs, space[\"lr_adam\"], space[\"lr_sgd\"])\n",
        "        if not lrs:\n",
        "            continue  # no quedan LRs válidos para este sub-espacio\n",
        "\n",
        "        # (Opcional) otra poda leve:\n",
        "        # Si activación es 'sigmoid' y hs muy pequeño, favorece LRs menores\n",
        "        if act == \"sigmoid\" and _is_small(hs):\n",
        "            lrs = [lr for lr in lrs if lr <= (5e-4 if opt==\"adam\" else 3e-3)]\n",
        "            if not lrs:\n",
        "                continue\n",
        "\n",
        "        for do in dropouts:\n",
        "            for lr in lrs:\n",
        "                yield {**cfg, \"dropout\": do, \"lr\": lr}\n",
        "\n",
        "def count_space_smart(space):\n",
        "    return sum(1 for _ in iter_space_smart(space))\n",
        "\n",
        "def count_space_with_lrs(space):\n",
        "    keys_base = [k for k in space.keys() if k not in (\"lr_adam\", \"lr_sgd\")]\n",
        "    total = 0\n",
        "    for vals in product(*[space[k] for k in keys_base]):\n",
        "        cfg = dict(zip(keys_base, vals))\n",
        "        total += len(space[\"lr_adam\"]) if cfg[\"optimizer_name\"].lower()==\"adam\" else len(space[\"lr_sgd\"])\n",
        "    return total\n",
        "\n",
        "print(\"Combos MLP (inteligentes):\", count_space_smart(mlp_space))\n",
        "print(\"Combos CNN:\", count_space_with_lrs(cnn_space))\n",
        "print(\"Total combos (aprox):\", count_space_smart(mlp_space) + count_space_with_lrs(cnn_space))\n",
        "\n",
        "results = []\n",
        "\n",
        "def run_cfg(cfg, save_artifacts=False):\n",
        "    print(\"\\n\" + \"=\"*72)\n",
        "    print(f\"RUN | model={cfg['model_type']} | img={cfg['img_size']} | bs={cfg['batch_size']} \"\n",
        "          f\"| epochs={cfg['epochs']} | opt={cfg['optimizer_name']} | lr={cfg['lr']} \"\n",
        "          f\"| aug={cfg['augment']} | act={cfg['activation']} | hs={cfg['hidden_sizes']} | do={cfg['dropout']} \"\n",
        "          f\"| use_pca={cfg.get('use_pca', False)} | pca_var={cfg.get('pca_var', None)} | whiten={cfg.get('pca_whiten', None)}\")\n",
        "    print(\"=\"*72)\n",
        "\n",
        "    t0 = time.time()\n",
        "    summary = run_experiment(\n",
        "        data_root=Path(DATA_ROOT),\n",
        "        img_size=cfg[\"img_size\"],\n",
        "        batch_size=cfg[\"batch_size\"],\n",
        "        epochs=cfg[\"epochs\"],\n",
        "        lr=cfg[\"lr\"],\n",
        "        optimizer_name=cfg[\"optimizer_name\"],\n",
        "        augment=cfg[\"augment\"],\n",
        "        activation=cfg[\"activation\"],\n",
        "        hidden_sizes=cfg[\"hidden_sizes\"],\n",
        "        dropout=cfg[\"dropout\"],\n",
        "        model_type=cfg[\"model_type\"],\n",
        "        num_workers=0,\n",
        "        seed=42,\n",
        "        device_str=\"cpu\",\n",
        "        save_artifacts=save_artifacts,\n",
        "        # PCA flags (en MLP ya están siempre en True en este espacio)\n",
        "        use_pca=cfg.get(\"use_pca\", False),\n",
        "        pca_var=cfg.get(\"pca_var\", 0.90),\n",
        "        pca_whiten=cfg.get(\"pca_whiten\", False)\n",
        "    )\n",
        "    wall = time.time() - t0\n",
        "    return {\n",
        "        **summary,\n",
        "        \"epochs\": cfg[\"epochs\"],\n",
        "        \"augment\": cfg[\"augment\"],\n",
        "        \"activation\": cfg[\"activation\"],\n",
        "        \"hidden_sizes\": cfg[\"hidden_sizes\"],\n",
        "        \"dropout\": cfg[\"dropout\"],\n",
        "        \"use_pca\": cfg.get(\"use_pca\", False),\n",
        "        \"pca_var\": cfg.get(\"pca_var\", None),\n",
        "        \"pca_whiten\": cfg.get(\"pca_whiten\", None),\n",
        "        \"wall_time_sec\": round(wall, 2),\n",
        "    }\n",
        "\n",
        "# ----- Ejecutar grid -----\n",
        "for cfg in iter_space_smart(mlp_space):\n",
        "    results.append(run_cfg(cfg, save_artifacts=False))\n",
        "\n",
        "for cfg in iter_space_with_lrs(cnn_space):\n",
        "    results.append(run_cfg(cfg, save_artifacts=False))\n",
        "\n",
        "df_results = pd.DataFrame(results)\n",
        "\n",
        "# ----- Vista compacta -----\n",
        "cols_view = [\n",
        "    \"model_type\",\"model\",\"accuracy\",\"precision_macro\",\"recall_macro\",\"f1_macro\",\"f1_weighted\",\n",
        "    \"time_per_epoch_sec\",\"wall_time_sec\",\"img_size\",\"batch_size\",\"optimizer\",\"lr\",\"augment\",\n",
        "    \"activation\",\"hidden_sizes\",\"dropout\",\"epochs\",\n",
        "    \"use_pca\",\"pca_var\",\"pca_whiten\"\n",
        "]\n",
        "display(df_results[cols_view].sort_values([\"model_type\",\"f1_macro\"], ascending=[True, False]))\n",
        "\n",
        "# ----- Elegir el mejor por tipo (f1_macro) -----\n",
        "best_idx_mlp = df_results[df_results[\"model_type\"]==\"mlp\"][\"f1_macro\"].idxmax()\n",
        "best_idx_cnn = df_results[df_results[\"model_type\"]==\"cnn\"][\"f1_macro\"].idxmax()\n",
        "best_mlp = df_results.loc[best_idx_mlp].to_dict()\n",
        "best_cnn = df_results.loc[best_idx_cnn].to_dict()\n",
        "\n",
        "print(\"\\n[Mejor MLP] ->\", best_mlp[\"model\"], \"| f1_macro=\", round(best_mlp[\"f1_macro\"],3))\n",
        "print(\"[Mejor CNN] ->\", best_cnn[\"model\"], \"| f1_macro=\", round(best_cnn[\"f1_macro\"],3))\n",
        "\n",
        "# ----- Re-ejecutar mejores con artefactos (curvas + report CSV) -----\n",
        "print(\"\\nRe-ejecutando mejores con save_artifacts=True (para la celda de visualización)...\")\n",
        "\n",
        "best_mlp_cfg = {\n",
        "    \"model_type\": \"mlp\",\n",
        "    \"img_size\":   int(best_mlp[\"img_size\"]),\n",
        "    \"batch_size\": int(best_mlp[\"batch_size\"]),\n",
        "    \"epochs\":     int(best_mlp[\"epochs\"]),\n",
        "    \"lr\":         float(best_mlp[\"lr\"]),\n",
        "    \"optimizer_name\": best_mlp[\"optimizer\"],\n",
        "    \"augment\":    bool(best_mlp[\"augment\"]),\n",
        "    \"activation\": best_mlp[\"activation\"],\n",
        "    \"hidden_sizes\": best_mlp[\"hidden_sizes\"],\n",
        "    \"dropout\":    float(best_mlp[\"dropout\"]) if best_mlp[\"dropout\"] is not None else 0.0,\n",
        "    \"use_pca\":    bool(best_mlp.get(\"use_pca\", False)),\n",
        "    \"pca_var\":    float(best_mlp[\"pca_var\"]) if best_mlp.get(\"pca_var\") is not None else 0.90,\n",
        "    \"pca_whiten\": bool(best_mlp.get(\"pca_whiten\", False)),\n",
        "}\n",
        "best_cnn_cfg = {\n",
        "    \"model_type\": \"cnn\",\n",
        "    \"img_size\":   int(best_cnn[\"img_size\"]),\n",
        "    \"batch_size\": int(best_cnn[\"batch_size\"]),\n",
        "    \"epochs\":     int(best_cnn[\"epochs\"]),\n",
        "    \"lr\":         float(best_cnn[\"lr\"]),\n",
        "    \"optimizer_name\": best_cnn[\"optimizer\"],\n",
        "    \"augment\":    bool(best_cnn[\"augment\"]),\n",
        "    \"activation\": \"relu\",\n",
        "    \"hidden_sizes\": [],\n",
        "    \"dropout\":    0.0,\n",
        "}\n",
        "\n",
        "best_mlp_summary = run_cfg(best_mlp_cfg, save_artifacts=True)\n",
        "best_cnn_summary = run_cfg(best_cnn_cfg, save_artifacts=True)\n",
        "\n",
        "best_title_mlp = best_mlp_summary[\"model\"]\n",
        "best_title_cnn = best_cnn_summary[\"model\"]\n",
        "print(\"\\n[Prefijos guardados] best_title_mlp =\", best_title_mlp, \"| best_title_cnn =\", best_title_cnn)\n"
      ],
      "metadata": {
        "id": "3LtdfvMViB2i",
        "outputId": "5292a1d6-b3e3-4ff7-cb3c-ca4368ec801d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combos MLP (inteligentes): 488\n",
            "Combos CNN: 20\n",
            "Total combos (aprox): 508\n",
            "\n",
            "========================================================================\n",
            "RUN | model=mlp | img=64 | bs=128 | epochs=30 | opt=adam | lr=0.005 | aug=True | act=relu | hs=[512, 256] | do=0.2 | use_pca=True | pca_var=0.95 | whiten=False\n",
            "========================================================================\n",
            "[Device] cpu | CUDA avail=False\n",
            "[Data] imgs=832 | clases=10 | img_size=64 | augment=True | use_pca=True\n",
            "[Split] train=665 | val=83 | test=84 | batch_size=128\n",
            "[PCA] var_exp≈0.9502 | dim: 12288 → 315 | whiten=False\n",
            "[Model] MLP_relu_hs[512, 256]_do0.2_PCA95 | optimizer=Adam(lr=0.005) | dropout=0.2 | activation=relu\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95] Ep 01/30 | Train loss 2.9324 acc 0.202 | Val loss 1.7056 acc 0.373 F1(macro) 0.343\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95] Ep 02/30 | Train loss 1.3616 acc 0.549 | Val loss 1.4695 acc 0.494 F1(macro) 0.482\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95] Ep 03/30 | Train loss 0.7646 acc 0.773 | Val loss 1.6260 acc 0.494 F1(macro) 0.500\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95] Ep 04/30 | Train loss 0.4258 acc 0.856 | Val loss 1.9770 acc 0.446 F1(macro) 0.454\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95] Ep 05/30 | Train loss 0.2014 acc 0.934 | Val loss 1.9904 acc 0.446 F1(macro) 0.463\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95] Ep 06/30 | Train loss 0.1163 acc 0.968 | Val loss 2.0799 acc 0.518 F1(macro) 0.507\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95] Ep 07/30 | Train loss 0.0641 acc 0.973 | Val loss 2.5978 acc 0.470 F1(macro) 0.475\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95] Ep 08/30 | Train loss 0.0754 acc 0.973 | Val loss 2.7180 acc 0.470 F1(macro) 0.477\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95] Ep 09/30 | Train loss 0.0460 acc 0.983 | Val loss 2.8051 acc 0.470 F1(macro) 0.482\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95] Ep 10/30 | Train loss 0.0441 acc 0.982 | Val loss 3.0771 acc 0.506 F1(macro) 0.500\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95] Ep 11/30 | Train loss 0.0393 acc 0.991 | Val loss 3.2528 acc 0.518 F1(macro) 0.520\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95] Ep 12/30 | Train loss 0.0322 acc 0.986 | Val loss 3.1246 acc 0.482 F1(macro) 0.455\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95] Ep 13/30 | Train loss 0.0333 acc 0.992 | Val loss 2.9031 acc 0.578 F1(macro) 0.563\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95] Ep 14/30 | Train loss 0.0149 acc 0.994 | Val loss 2.7380 acc 0.506 F1(macro) 0.501\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95] Ep 15/30 | Train loss 0.0212 acc 0.992 | Val loss 2.8705 acc 0.530 F1(macro) 0.536\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95] Ep 16/30 | Train loss 0.0139 acc 0.997 | Val loss 3.1707 acc 0.494 F1(macro) 0.497\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95] Ep 17/30 | Train loss 0.0073 acc 1.000 | Val loss 3.4933 acc 0.482 F1(macro) 0.492\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95] Ep 18/30 | Train loss 0.0064 acc 0.998 | Val loss 3.5670 acc 0.470 F1(macro) 0.478\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95] Ep 19/30 | Train loss 0.0197 acc 0.994 | Val loss 3.5776 acc 0.482 F1(macro) 0.480\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95] Ep 20/30 | Train loss 0.0117 acc 0.992 | Val loss 3.4502 acc 0.494 F1(macro) 0.499\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95] Ep 21/30 | Train loss 0.0254 acc 0.992 | Val loss 3.4701 acc 0.506 F1(macro) 0.513\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95] Ep 22/30 | Train loss 0.0160 acc 0.994 | Val loss 3.3219 acc 0.530 F1(macro) 0.538\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95] Ep 23/30 | Train loss 0.0278 acc 0.986 | Val loss 3.3131 acc 0.554 F1(macro) 0.561\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95] Ep 24/30 | Train loss 0.0253 acc 0.992 | Val loss 3.6376 acc 0.542 F1(macro) 0.541\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95] Ep 25/30 | Train loss 0.0147 acc 0.995 | Val loss 3.8567 acc 0.518 F1(macro) 0.518\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95] Ep 26/30 | Train loss 0.0450 acc 0.986 | Val loss 3.7554 acc 0.446 F1(macro) 0.447\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95] Ep 27/30 | Train loss 0.0399 acc 0.979 | Val loss 3.6449 acc 0.494 F1(macro) 0.507\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95] Ep 28/30 | Train loss 0.0381 acc 0.989 | Val loss 3.2956 acc 0.506 F1(macro) 0.513\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95] Ep 29/30 | Train loss 0.0273 acc 0.991 | Val loss 3.8061 acc 0.446 F1(macro) 0.437\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95] Ep 30/30 | Train loss 0.0934 acc 0.986 | Val loss 3.6499 acc 0.494 F1(macro) 0.508\n",
            "[Tiempo] ~0.05s/epoch | best Val F1(macro)=0.563\n",
            "[Test] acc=0.476 | F1(macro)=0.469 | F1(weighted)=0.460\n",
            "\n",
            "MLP_relu_hs[512, 256]_do0.2_PCA95 - Confusion Matrix — Matriz de confusión\n",
            "          pred_001  pred_002  pred_003  pred_004  pred_005  pred_006  pred_007  pred_008  pred_009  pred_010\n",
            "true_001         6         0         0         0         1         0         0         0         0         1\n",
            "true_002         0         2         3         0         1         0         0         1         0         3\n",
            "true_003         0         0         1         0         0         1         1         0         2         1\n",
            "true_004         1         1         1         3         1         0         0         0         2         0\n",
            "true_005         0         0         1         1         5         0         2         0         0         0\n",
            "true_006         1         1         0         1         0         7         0         0         0         0\n",
            "true_007         0         0         0         0         0         2         6         0         0         1\n",
            "true_008         0         0         0         0         0         0         0         4         0         1\n",
            "true_009         0         0         1         0         1         6         0         0         1         0\n",
            "true_010         1         0         0         2         0         0         0         0         1         5\n",
            "\n",
            "[Classification report]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         001      0.667     0.750     0.706         8\n",
            "         002      0.500     0.200     0.286        10\n",
            "         003      0.143     0.167     0.154         6\n",
            "         004      0.429     0.333     0.375         9\n",
            "         005      0.556     0.556     0.556         9\n",
            "         006      0.438     0.700     0.538        10\n",
            "         007      0.667     0.667     0.667         9\n",
            "         008      0.800     0.800     0.800         5\n",
            "         009      0.167     0.111     0.133         9\n",
            "         010      0.417     0.556     0.476         9\n",
            "\n",
            "    accuracy                          0.476        84\n",
            "   macro avg      0.478     0.484     0.469        84\n",
            "weighted avg      0.472     0.476     0.460        84\n",
            "\n",
            "\n",
            "========================================================================\n",
            "RUN | model=mlp | img=64 | bs=128 | epochs=30 | opt=adam | lr=0.0003 | aug=True | act=relu | hs=[512, 256] | do=0.2 | use_pca=True | pca_var=0.95 | whiten=False\n",
            "========================================================================\n",
            "[Device] cpu | CUDA avail=False\n",
            "[Data] imgs=832 | clases=10 | img_size=64 | augment=True | use_pca=True\n",
            "[Split] train=665 | val=83 | test=84 | batch_size=128\n",
            "[PCA] var_exp≈0.9502 | dim: 12288 → 315 | whiten=False\n",
            "[Model] MLP_relu_hs[512, 256]_do0.2_PCA95 | optimizer=Adam(lr=0.0003) | dropout=0.2 | activation=relu\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95] Ep 01/30 | Train loss 2.4822 acc 0.114 | Val loss 2.1455 acc 0.265 F1(macro) 0.236\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95] Ep 02/30 | Train loss 2.0650 acc 0.262 | Val loss 2.0166 acc 0.373 F1(macro) 0.346\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95] Ep 03/30 | Train loss 1.7969 acc 0.395 | Val loss 1.9221 acc 0.289 F1(macro) 0.264\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95] Ep 04/30 | Train loss 1.6208 acc 0.493 | Val loss 1.8343 acc 0.386 F1(macro) 0.365\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95] Ep 05/30 | Train loss 1.4924 acc 0.529 | Val loss 1.7346 acc 0.422 F1(macro) 0.429\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95] Ep 06/30 | Train loss 1.3424 acc 0.605 | Val loss 1.6619 acc 0.422 F1(macro) 0.405\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95] Ep 07/30 | Train loss 1.2050 acc 0.647 | Val loss 1.6063 acc 0.434 F1(macro) 0.434\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95] Ep 08/30 | Train loss 1.0703 acc 0.701 | Val loss 1.5624 acc 0.434 F1(macro) 0.446\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95] Ep 09/30 | Train loss 0.9657 acc 0.750 | Val loss 1.5403 acc 0.446 F1(macro) 0.459\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95] Ep 10/30 | Train loss 0.8369 acc 0.811 | Val loss 1.5183 acc 0.434 F1(macro) 0.433\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95] Ep 11/30 | Train loss 0.7437 acc 0.818 | Val loss 1.4879 acc 0.494 F1(macro) 0.487\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95] Ep 12/30 | Train loss 0.6556 acc 0.865 | Val loss 1.4871 acc 0.494 F1(macro) 0.491\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95] Ep 13/30 | Train loss 0.6008 acc 0.868 | Val loss 1.4622 acc 0.506 F1(macro) 0.510\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95] Ep 14/30 | Train loss 0.5151 acc 0.901 | Val loss 1.4571 acc 0.482 F1(macro) 0.493\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95] Ep 15/30 | Train loss 0.4866 acc 0.904 | Val loss 1.4337 acc 0.470 F1(macro) 0.467\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95] Ep 16/30 | Train loss 0.4043 acc 0.934 | Val loss 1.4225 acc 0.530 F1(macro) 0.531\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95] Ep 17/30 | Train loss 0.3552 acc 0.935 | Val loss 1.4111 acc 0.566 F1(macro) 0.563\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95] Ep 18/30 | Train loss 0.3240 acc 0.938 | Val loss 1.4251 acc 0.494 F1(macro) 0.490\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95] Ep 19/30 | Train loss 0.2940 acc 0.947 | Val loss 1.4389 acc 0.506 F1(macro) 0.506\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95] Ep 20/30 | Train loss 0.2559 acc 0.950 | Val loss 1.4461 acc 0.506 F1(macro) 0.511\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95] Ep 21/30 | Train loss 0.2353 acc 0.965 | Val loss 1.4769 acc 0.494 F1(macro) 0.495\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95] Ep 22/30 | Train loss 0.2257 acc 0.968 | Val loss 1.4674 acc 0.482 F1(macro) 0.491\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95] Ep 23/30 | Train loss 0.1800 acc 0.982 | Val loss 1.4671 acc 0.482 F1(macro) 0.487\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95] Ep 24/30 | Train loss 0.1662 acc 0.977 | Val loss 1.4595 acc 0.482 F1(macro) 0.486\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95] Ep 25/30 | Train loss 0.1385 acc 0.980 | Val loss 1.4653 acc 0.494 F1(macro) 0.498\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95] Ep 26/30 | Train loss 0.1357 acc 0.976 | Val loss 1.4694 acc 0.494 F1(macro) 0.501\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95] Ep 27/30 | Train loss 0.1082 acc 0.988 | Val loss 1.4748 acc 0.494 F1(macro) 0.493\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95] Ep 28/30 | Train loss 0.1065 acc 0.986 | Val loss 1.4816 acc 0.506 F1(macro) 0.504\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95] Ep 29/30 | Train loss 0.1036 acc 0.992 | Val loss 1.4990 acc 0.506 F1(macro) 0.511\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95] Ep 30/30 | Train loss 0.0933 acc 0.991 | Val loss 1.5219 acc 0.494 F1(macro) 0.500\n",
            "[Tiempo] ~0.05s/epoch | best Val F1(macro)=0.563\n",
            "[Test] acc=0.536 | F1(macro)=0.514 | F1(weighted)=0.515\n",
            "\n",
            "MLP_relu_hs[512, 256]_do0.2_PCA95 - Confusion Matrix — Matriz de confusión\n",
            "          pred_001  pred_002  pred_003  pred_004  pred_005  pred_006  pred_007  pred_008  pred_009  pred_010\n",
            "true_001         4         0         0         1         0         0         0         0         0         3\n",
            "true_002         0         7         0         0         1         0         0         1         0         1\n",
            "true_003         0         2         1         0         0         1         1         1         0         0\n",
            "true_004         2         1         0         3         1         0         1         0         0         1\n",
            "true_005         0         0         1         1         3         1         1         0         0         2\n",
            "true_006         0         1         0         2         0         7         0         0         0         0\n",
            "true_007         0         0         2         1         0         0         6         0         0         0\n",
            "true_008         0         0         0         0         0         0         0         5         0         0\n",
            "true_009         0         1         0         1         0         4         0         1         2         0\n",
            "true_010         0         0         0         1         0         0         0         0         1         7\n",
            "\n",
            "[Classification report]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         001      0.667     0.500     0.571         8\n",
            "         002      0.583     0.700     0.636        10\n",
            "         003      0.250     0.167     0.200         6\n",
            "         004      0.300     0.333     0.316         9\n",
            "         005      0.600     0.333     0.429         9\n",
            "         006      0.538     0.700     0.609        10\n",
            "         007      0.667     0.667     0.667         9\n",
            "         008      0.625     1.000     0.769         5\n",
            "         009      0.667     0.222     0.333         9\n",
            "         010      0.500     0.778     0.609         9\n",
            "\n",
            "    accuracy                          0.536        84\n",
            "   macro avg      0.540     0.540     0.514        84\n",
            "weighted avg      0.545     0.536     0.515        84\n",
            "\n",
            "\n",
            "========================================================================\n",
            "RUN | model=mlp | img=64 | bs=128 | epochs=30 | opt=adam | lr=0.0001 | aug=True | act=relu | hs=[512, 256] | do=0.2 | use_pca=True | pca_var=0.95 | whiten=False\n",
            "========================================================================\n",
            "[Device] cpu | CUDA avail=False\n",
            "[Data] imgs=832 | clases=10 | img_size=64 | augment=True | use_pca=True\n",
            "[Split] train=665 | val=83 | test=84 | batch_size=128\n",
            "[PCA] var_exp≈0.9502 | dim: 12288 → 315 | whiten=False\n",
            "[Model] MLP_relu_hs[512, 256]_do0.2_PCA95 | optimizer=Adam(lr=0.0001) | dropout=0.2 | activation=relu\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95] Ep 01/30 | Train loss 2.5817 acc 0.089 | Val loss 2.2896 acc 0.120 F1(macro) 0.096\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95] Ep 02/30 | Train loss 2.3502 acc 0.134 | Val loss 2.2027 acc 0.205 F1(macro) 0.169\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95] Ep 03/30 | Train loss 2.2124 acc 0.191 | Val loss 2.1429 acc 0.301 F1(macro) 0.265\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95] Ep 04/30 | Train loss 2.1034 acc 0.230 | Val loss 2.0935 acc 0.325 F1(macro) 0.299\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95] Ep 05/30 | Train loss 2.0416 acc 0.305 | Val loss 2.0515 acc 0.229 F1(macro) 0.215\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95] Ep 06/30 | Train loss 1.9435 acc 0.308 | Val loss 2.0136 acc 0.265 F1(macro) 0.245\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95] Ep 07/30 | Train loss 1.8858 acc 0.362 | Val loss 1.9752 acc 0.277 F1(macro) 0.254\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95] Ep 08/30 | Train loss 1.7991 acc 0.409 | Val loss 1.9360 acc 0.301 F1(macro) 0.280\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95] Ep 09/30 | Train loss 1.7318 acc 0.445 | Val loss 1.9043 acc 0.325 F1(macro) 0.317\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95] Ep 10/30 | Train loss 1.6716 acc 0.472 | Val loss 1.8758 acc 0.337 F1(macro) 0.326\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95] Ep 11/30 | Train loss 1.6019 acc 0.484 | Val loss 1.8460 acc 0.349 F1(macro) 0.334\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95] Ep 12/30 | Train loss 1.5455 acc 0.525 | Val loss 1.8228 acc 0.410 F1(macro) 0.394\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95] Ep 13/30 | Train loss 1.5171 acc 0.526 | Val loss 1.7990 acc 0.434 F1(macro) 0.414\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95] Ep 14/30 | Train loss 1.4350 acc 0.565 | Val loss 1.7796 acc 0.434 F1(macro) 0.423\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95] Ep 15/30 | Train loss 1.4139 acc 0.573 | Val loss 1.7525 acc 0.458 F1(macro) 0.449\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95] Ep 16/30 | Train loss 1.3256 acc 0.638 | Val loss 1.7256 acc 0.446 F1(macro) 0.435\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95] Ep 17/30 | Train loss 1.2899 acc 0.623 | Val loss 1.7004 acc 0.446 F1(macro) 0.436\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95] Ep 18/30 | Train loss 1.2644 acc 0.647 | Val loss 1.6822 acc 0.434 F1(macro) 0.428\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95] Ep 19/30 | Train loss 1.2250 acc 0.662 | Val loss 1.6631 acc 0.434 F1(macro) 0.437\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95] Ep 20/30 | Train loss 1.1572 acc 0.714 | Val loss 1.6436 acc 0.446 F1(macro) 0.453\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95] Ep 21/30 | Train loss 1.1415 acc 0.684 | Val loss 1.6289 acc 0.434 F1(macro) 0.443\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95] Ep 22/30 | Train loss 1.0999 acc 0.698 | Val loss 1.6128 acc 0.470 F1(macro) 0.469\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95] Ep 23/30 | Train loss 1.0506 acc 0.716 | Val loss 1.6022 acc 0.458 F1(macro) 0.458\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95] Ep 24/30 | Train loss 1.0051 acc 0.759 | Val loss 1.5877 acc 0.446 F1(macro) 0.440\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95] Ep 25/30 | Train loss 0.9521 acc 0.755 | Val loss 1.5683 acc 0.458 F1(macro) 0.451\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95] Ep 26/30 | Train loss 0.9249 acc 0.776 | Val loss 1.5476 acc 0.470 F1(macro) 0.471\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95] Ep 27/30 | Train loss 0.8595 acc 0.805 | Val loss 1.5282 acc 0.470 F1(macro) 0.472\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95] Ep 28/30 | Train loss 0.8328 acc 0.808 | Val loss 1.5122 acc 0.470 F1(macro) 0.472\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95] Ep 29/30 | Train loss 0.8308 acc 0.797 | Val loss 1.4989 acc 0.458 F1(macro) 0.459\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95] Ep 30/30 | Train loss 0.7970 acc 0.805 | Val loss 1.5016 acc 0.470 F1(macro) 0.470\n",
            "[Tiempo] ~0.04s/epoch | best Val F1(macro)=0.472\n",
            "[Test] acc=0.488 | F1(macro)=0.476 | F1(weighted)=0.467\n",
            "\n",
            "MLP_relu_hs[512, 256]_do0.2_PCA95 - Confusion Matrix — Matriz de confusión\n",
            "          pred_001  pred_002  pred_003  pred_004  pred_005  pred_006  pred_007  pred_008  pred_009  pred_010\n",
            "true_001         4         0         0         0         0         0         0         0         0         4\n",
            "true_002         0         5         0         0         1         0         3         0         0         1\n",
            "true_003         0         1         1         0         0         1         2         1         0         0\n",
            "true_004         1         1         1         2         1         1         1         0         0         1\n",
            "true_005         0         1         0         0         3         2         1         0         0         2\n",
            "true_006         0         1         0         2         0         7         0         0         0         0\n",
            "true_007         0         0         0         1         0         0         6         0         1         1\n",
            "true_008         0         0         0         0         0         0         0         5         0         0\n",
            "true_009         0         1         0         1         0         4         0         1         2         0\n",
            "true_010         0         0         0         1         1         0         0         0         1         6\n",
            "\n",
            "[Classification report]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         001      0.800     0.500     0.615         8\n",
            "         002      0.500     0.500     0.500        10\n",
            "         003      0.500     0.167     0.250         6\n",
            "         004      0.286     0.222     0.250         9\n",
            "         005      0.500     0.333     0.400         9\n",
            "         006      0.467     0.700     0.560        10\n",
            "         007      0.462     0.667     0.545         9\n",
            "         008      0.714     1.000     0.833         5\n",
            "         009      0.500     0.222     0.308         9\n",
            "         010      0.400     0.667     0.500         9\n",
            "\n",
            "    accuracy                          0.488        84\n",
            "   macro avg      0.513     0.498     0.476        84\n",
            "weighted avg      0.500     0.488     0.467        84\n",
            "\n",
            "\n",
            "========================================================================\n",
            "RUN | model=mlp | img=64 | bs=128 | epochs=30 | opt=adam | lr=0.005 | aug=True | act=relu | hs=[512, 256] | do=0.4 | use_pca=True | pca_var=0.95 | whiten=False\n",
            "========================================================================\n",
            "[Device] cpu | CUDA avail=False\n",
            "[Data] imgs=832 | clases=10 | img_size=64 | augment=True | use_pca=True\n",
            "[Split] train=665 | val=83 | test=84 | batch_size=128\n",
            "[PCA] var_exp≈0.9502 | dim: 12288 → 315 | whiten=False\n",
            "[Model] MLP_relu_hs[512, 256]_do0.4_PCA95 | optimizer=Adam(lr=0.005) | dropout=0.4 | activation=relu\n",
            "[MLP_relu_hs[512, 256]_do0.4_PCA95] Ep 01/30 | Train loss 2.8206 acc 0.191 | Val loss 1.8154 acc 0.361 F1(macro) 0.302\n",
            "[MLP_relu_hs[512, 256]_do0.4_PCA95] Ep 02/30 | Train loss 1.5491 acc 0.490 | Val loss 1.5775 acc 0.434 F1(macro) 0.451\n",
            "[MLP_relu_hs[512, 256]_do0.4_PCA95] Ep 03/30 | Train loss 1.0606 acc 0.657 | Val loss 1.4867 acc 0.470 F1(macro) 0.463\n",
            "[MLP_relu_hs[512, 256]_do0.4_PCA95] Ep 04/30 | Train loss 0.7603 acc 0.744 | Val loss 1.5564 acc 0.470 F1(macro) 0.494\n",
            "[MLP_relu_hs[512, 256]_do0.4_PCA95] Ep 05/30 | Train loss 0.5114 acc 0.826 | Val loss 1.7068 acc 0.470 F1(macro) 0.476\n",
            "[MLP_relu_hs[512, 256]_do0.4_PCA95] Ep 06/30 | Train loss 0.3225 acc 0.895 | Val loss 1.9924 acc 0.458 F1(macro) 0.463\n",
            "[MLP_relu_hs[512, 256]_do0.4_PCA95] Ep 07/30 | Train loss 0.2419 acc 0.931 | Val loss 2.0422 acc 0.434 F1(macro) 0.441\n",
            "[MLP_relu_hs[512, 256]_do0.4_PCA95] Ep 08/30 | Train loss 0.1919 acc 0.941 | Val loss 2.2416 acc 0.506 F1(macro) 0.515\n",
            "[MLP_relu_hs[512, 256]_do0.4_PCA95] Ep 09/30 | Train loss 0.2421 acc 0.923 | Val loss 2.5557 acc 0.446 F1(macro) 0.446\n",
            "[MLP_relu_hs[512, 256]_do0.4_PCA95] Ep 10/30 | Train loss 0.2397 acc 0.949 | Val loss 2.5763 acc 0.446 F1(macro) 0.453\n",
            "[MLP_relu_hs[512, 256]_do0.4_PCA95] Ep 11/30 | Train loss 0.1816 acc 0.938 | Val loss 2.5130 acc 0.506 F1(macro) 0.504\n",
            "[MLP_relu_hs[512, 256]_do0.4_PCA95] Ep 12/30 | Train loss 0.1714 acc 0.943 | Val loss 2.8061 acc 0.446 F1(macro) 0.450\n",
            "[MLP_relu_hs[512, 256]_do0.4_PCA95] Ep 13/30 | Train loss 0.1436 acc 0.953 | Val loss 2.7979 acc 0.373 F1(macro) 0.359\n",
            "[MLP_relu_hs[512, 256]_do0.4_PCA95] Ep 14/30 | Train loss 0.2061 acc 0.944 | Val loss 2.6795 acc 0.410 F1(macro) 0.421\n",
            "[MLP_relu_hs[512, 256]_do0.4_PCA95] Ep 15/30 | Train loss 0.1464 acc 0.953 | Val loss 2.7090 acc 0.434 F1(macro) 0.433\n",
            "[MLP_relu_hs[512, 256]_do0.4_PCA95] Ep 16/30 | Train loss 0.1385 acc 0.955 | Val loss 2.9481 acc 0.482 F1(macro) 0.480\n",
            "[MLP_relu_hs[512, 256]_do0.4_PCA95] Ep 17/30 | Train loss 0.1386 acc 0.958 | Val loss 3.1037 acc 0.446 F1(macro) 0.442\n",
            "[MLP_relu_hs[512, 256]_do0.4_PCA95] Ep 18/30 | Train loss 0.1584 acc 0.946 | Val loss 3.1103 acc 0.494 F1(macro) 0.481\n",
            "[MLP_relu_hs[512, 256]_do0.4_PCA95] Ep 19/30 | Train loss 0.1398 acc 0.959 | Val loss 2.9968 acc 0.458 F1(macro) 0.451\n",
            "[MLP_relu_hs[512, 256]_do0.4_PCA95] Ep 20/30 | Train loss 0.1453 acc 0.953 | Val loss 3.1787 acc 0.506 F1(macro) 0.513\n",
            "[MLP_relu_hs[512, 256]_do0.4_PCA95] Ep 21/30 | Train loss 0.1892 acc 0.958 | Val loss 3.5908 acc 0.446 F1(macro) 0.456\n",
            "[MLP_relu_hs[512, 256]_do0.4_PCA95] Ep 22/30 | Train loss 0.2244 acc 0.941 | Val loss 3.4340 acc 0.458 F1(macro) 0.463\n",
            "[MLP_relu_hs[512, 256]_do0.4_PCA95] Ep 23/30 | Train loss 0.1864 acc 0.953 | Val loss 3.6749 acc 0.458 F1(macro) 0.459\n",
            "[MLP_relu_hs[512, 256]_do0.4_PCA95] Ep 24/30 | Train loss 0.1120 acc 0.968 | Val loss 3.6520 acc 0.422 F1(macro) 0.414\n",
            "[MLP_relu_hs[512, 256]_do0.4_PCA95] Ep 25/30 | Train loss 0.1451 acc 0.962 | Val loss 3.4484 acc 0.506 F1(macro) 0.501\n",
            "[MLP_relu_hs[512, 256]_do0.4_PCA95] Ep 26/30 | Train loss 0.1668 acc 0.955 | Val loss 3.9380 acc 0.494 F1(macro) 0.444\n",
            "[MLP_relu_hs[512, 256]_do0.4_PCA95] Ep 27/30 | Train loss 0.1050 acc 0.959 | Val loss 4.4019 acc 0.446 F1(macro) 0.419\n",
            "[MLP_relu_hs[512, 256]_do0.4_PCA95] Ep 28/30 | Train loss 0.0874 acc 0.974 | Val loss 4.6815 acc 0.458 F1(macro) 0.428\n",
            "[MLP_relu_hs[512, 256]_do0.4_PCA95] Ep 29/30 | Train loss 0.1699 acc 0.950 | Val loss 4.4036 acc 0.422 F1(macro) 0.412\n",
            "[MLP_relu_hs[512, 256]_do0.4_PCA95] Ep 30/30 | Train loss 0.1405 acc 0.970 | Val loss 4.6687 acc 0.422 F1(macro) 0.419\n",
            "[Tiempo] ~0.05s/epoch | best Val F1(macro)=0.515\n",
            "[Test] acc=0.571 | F1(macro)=0.545 | F1(weighted)=0.560\n",
            "\n",
            "MLP_relu_hs[512, 256]_do0.4_PCA95 - Confusion Matrix — Matriz de confusión\n",
            "          pred_001  pred_002  pred_003  pred_004  pred_005  pred_006  pred_007  pred_008  pred_009  pred_010\n",
            "true_001         6         0         0         1         1         0         0         0         0         0\n",
            "true_002         0         8         0         0         1         0         0         1         0         0\n",
            "true_003         0         1         0         1         1         0         0         1         2         0\n",
            "true_004         1         1         0         2         0         0         0         0         4         1\n",
            "true_005         0         0         0         0         7         0         1         0         0         1\n",
            "true_006         0         0         0         3         0         6         1         0         0         0\n",
            "true_007         0         0         1         0         0         1         6         1         0         0\n",
            "true_008         0         0         0         0         0         0         0         4         0         1\n",
            "true_009         0         0         0         2         0         3         0         0         4         0\n",
            "true_010         1         0         0         2         0         0         0         0         1         5\n",
            "\n",
            "[Classification report]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         001      0.750     0.750     0.750         8\n",
            "         002      0.800     0.800     0.800        10\n",
            "         003      0.000     0.000     0.000         6\n",
            "         004      0.182     0.222     0.200         9\n",
            "         005      0.700     0.778     0.737         9\n",
            "         006      0.600     0.600     0.600        10\n",
            "         007      0.750     0.667     0.706         9\n",
            "         008      0.571     0.800     0.667         5\n",
            "         009      0.364     0.444     0.400         9\n",
            "         010      0.625     0.556     0.588         9\n",
            "\n",
            "    accuracy                          0.571        84\n",
            "   macro avg      0.534     0.562     0.545        84\n",
            "weighted avg      0.553     0.571     0.560        84\n",
            "\n",
            "\n",
            "========================================================================\n",
            "RUN | model=mlp | img=64 | bs=128 | epochs=30 | opt=adam | lr=0.0003 | aug=True | act=relu | hs=[512, 256] | do=0.4 | use_pca=True | pca_var=0.95 | whiten=False\n",
            "========================================================================\n",
            "[Device] cpu | CUDA avail=False\n",
            "[Data] imgs=832 | clases=10 | img_size=64 | augment=True | use_pca=True\n",
            "[Split] train=665 | val=83 | test=84 | batch_size=128\n",
            "[PCA] var_exp≈0.9502 | dim: 12288 → 315 | whiten=False\n",
            "[Model] MLP_relu_hs[512, 256]_do0.4_PCA95 | optimizer=Adam(lr=0.0003) | dropout=0.4 | activation=relu\n",
            "[MLP_relu_hs[512, 256]_do0.4_PCA95] Ep 01/30 | Train loss 2.6762 acc 0.093 | Val loss 2.1985 acc 0.205 F1(macro) 0.148\n",
            "[MLP_relu_hs[512, 256]_do0.4_PCA95] Ep 02/30 | Train loss 2.3212 acc 0.203 | Val loss 2.0941 acc 0.313 F1(macro) 0.265\n",
            "[MLP_relu_hs[512, 256]_do0.4_PCA95] Ep 03/30 | Train loss 2.0943 acc 0.254 | Val loss 2.0155 acc 0.289 F1(macro) 0.239\n",
            "[MLP_relu_hs[512, 256]_do0.4_PCA95] Ep 04/30 | Train loss 1.9555 acc 0.316 | Val loss 1.9584 acc 0.217 F1(macro) 0.190\n",
            "[MLP_relu_hs[512, 256]_do0.4_PCA95] Ep 05/30 | Train loss 1.8976 acc 0.329 | Val loss 1.8877 acc 0.337 F1(macro) 0.326\n",
            "[MLP_relu_hs[512, 256]_do0.4_PCA95] Ep 06/30 | Train loss 1.7411 acc 0.405 | Val loss 1.8094 acc 0.349 F1(macro) 0.316\n",
            "[MLP_relu_hs[512, 256]_do0.4_PCA95] Ep 07/30 | Train loss 1.6507 acc 0.444 | Val loss 1.7541 acc 0.410 F1(macro) 0.376\n",
            "[MLP_relu_hs[512, 256]_do0.4_PCA95] Ep 08/30 | Train loss 1.6013 acc 0.469 | Val loss 1.7099 acc 0.446 F1(macro) 0.434\n",
            "[MLP_relu_hs[512, 256]_do0.4_PCA95] Ep 09/30 | Train loss 1.4768 acc 0.544 | Val loss 1.6755 acc 0.458 F1(macro) 0.450\n",
            "[MLP_relu_hs[512, 256]_do0.4_PCA95] Ep 10/30 | Train loss 1.4058 acc 0.564 | Val loss 1.6510 acc 0.446 F1(macro) 0.447\n",
            "[MLP_relu_hs[512, 256]_do0.4_PCA95] Ep 11/30 | Train loss 1.3494 acc 0.552 | Val loss 1.6179 acc 0.422 F1(macro) 0.417\n",
            "[MLP_relu_hs[512, 256]_do0.4_PCA95] Ep 12/30 | Train loss 1.2603 acc 0.618 | Val loss 1.5920 acc 0.470 F1(macro) 0.463\n",
            "[MLP_relu_hs[512, 256]_do0.4_PCA95] Ep 13/30 | Train loss 1.1870 acc 0.641 | Val loss 1.5673 acc 0.458 F1(macro) 0.447\n",
            "[MLP_relu_hs[512, 256]_do0.4_PCA95] Ep 14/30 | Train loss 1.0941 acc 0.641 | Val loss 1.5407 acc 0.458 F1(macro) 0.449\n",
            "[MLP_relu_hs[512, 256]_do0.4_PCA95] Ep 15/30 | Train loss 1.0587 acc 0.662 | Val loss 1.5165 acc 0.434 F1(macro) 0.428\n",
            "[MLP_relu_hs[512, 256]_do0.4_PCA95] Ep 16/30 | Train loss 0.9726 acc 0.698 | Val loss 1.5008 acc 0.446 F1(macro) 0.439\n",
            "[MLP_relu_hs[512, 256]_do0.4_PCA95] Ep 17/30 | Train loss 0.9509 acc 0.701 | Val loss 1.4806 acc 0.494 F1(macro) 0.486\n",
            "[MLP_relu_hs[512, 256]_do0.4_PCA95] Ep 18/30 | Train loss 0.8815 acc 0.752 | Val loss 1.4675 acc 0.518 F1(macro) 0.516\n",
            "[MLP_relu_hs[512, 256]_do0.4_PCA95] Ep 19/30 | Train loss 0.8278 acc 0.753 | Val loss 1.4579 acc 0.506 F1(macro) 0.506\n",
            "[MLP_relu_hs[512, 256]_do0.4_PCA95] Ep 20/30 | Train loss 0.7525 acc 0.783 | Val loss 1.4471 acc 0.506 F1(macro) 0.508\n",
            "[MLP_relu_hs[512, 256]_do0.4_PCA95] Ep 21/30 | Train loss 0.7218 acc 0.776 | Val loss 1.4455 acc 0.470 F1(macro) 0.468\n",
            "[MLP_relu_hs[512, 256]_do0.4_PCA95] Ep 22/30 | Train loss 0.6852 acc 0.795 | Val loss 1.4385 acc 0.458 F1(macro) 0.457\n",
            "[MLP_relu_hs[512, 256]_do0.4_PCA95] Ep 23/30 | Train loss 0.6080 acc 0.824 | Val loss 1.4439 acc 0.482 F1(macro) 0.487\n",
            "[MLP_relu_hs[512, 256]_do0.4_PCA95] Ep 24/30 | Train loss 0.5880 acc 0.824 | Val loss 1.4398 acc 0.494 F1(macro) 0.504\n",
            "[MLP_relu_hs[512, 256]_do0.4_PCA95] Ep 25/30 | Train loss 0.5181 acc 0.863 | Val loss 1.4431 acc 0.446 F1(macro) 0.450\n",
            "[MLP_relu_hs[512, 256]_do0.4_PCA95] Ep 26/30 | Train loss 0.5318 acc 0.850 | Val loss 1.4363 acc 0.458 F1(macro) 0.464\n",
            "[MLP_relu_hs[512, 256]_do0.4_PCA95] Ep 27/30 | Train loss 0.4942 acc 0.877 | Val loss 1.4289 acc 0.506 F1(macro) 0.513\n",
            "[MLP_relu_hs[512, 256]_do0.4_PCA95] Ep 28/30 | Train loss 0.4323 acc 0.886 | Val loss 1.4205 acc 0.482 F1(macro) 0.490\n",
            "[MLP_relu_hs[512, 256]_do0.4_PCA95] Ep 29/30 | Train loss 0.4283 acc 0.892 | Val loss 1.4304 acc 0.506 F1(macro) 0.520\n",
            "[MLP_relu_hs[512, 256]_do0.4_PCA95] Ep 30/30 | Train loss 0.3964 acc 0.890 | Val loss 1.4349 acc 0.518 F1(macro) 0.526\n",
            "[Tiempo] ~0.04s/epoch | best Val F1(macro)=0.526\n",
            "[Test] acc=0.524 | F1(macro)=0.498 | F1(weighted)=0.495\n",
            "\n",
            "MLP_relu_hs[512, 256]_do0.4_PCA95 - Confusion Matrix — Matriz de confusión\n",
            "          pred_001  pred_002  pred_003  pred_004  pred_005  pred_006  pred_007  pred_008  pred_009  pred_010\n",
            "true_001         4         0         0         0         0         0         0         0         0         4\n",
            "true_002         0         6         0         0         1         0         1         1         0         1\n",
            "true_003         0         2         1         0         0         1         1         1         0         0\n",
            "true_004         1         1         0         4         1         0         1         0         0         1\n",
            "true_005         0         0         0         2         3         1         1         0         0         2\n",
            "true_006         0         1         0         2         0         7         0         0         0         0\n",
            "true_007         0         0         1         1         0         0         6         0         0         1\n",
            "true_008         0         0         0         0         0         0         0         5         0         0\n",
            "true_009         0         1         0         0         1         5         0         1         1         0\n",
            "true_010         0         0         0         1         0         0         0         0         1         7\n",
            "\n",
            "[Classification report]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         001      0.800     0.500     0.615         8\n",
            "         002      0.545     0.600     0.571        10\n",
            "         003      0.500     0.167     0.250         6\n",
            "         004      0.400     0.444     0.421         9\n",
            "         005      0.500     0.333     0.400         9\n",
            "         006      0.500     0.700     0.583        10\n",
            "         007      0.600     0.667     0.632         9\n",
            "         008      0.625     1.000     0.769         5\n",
            "         009      0.500     0.111     0.182         9\n",
            "         010      0.438     0.778     0.560         9\n",
            "\n",
            "    accuracy                          0.524        84\n",
            "   macro avg      0.541     0.530     0.498        84\n",
            "weighted avg      0.535     0.524     0.495        84\n",
            "\n",
            "\n",
            "========================================================================\n",
            "RUN | model=mlp | img=64 | bs=128 | epochs=30 | opt=adam | lr=0.0001 | aug=True | act=relu | hs=[512, 256] | do=0.4 | use_pca=True | pca_var=0.95 | whiten=False\n",
            "========================================================================\n",
            "[Device] cpu | CUDA avail=False\n",
            "[Data] imgs=832 | clases=10 | img_size=64 | augment=True | use_pca=True\n",
            "[Split] train=665 | val=83 | test=84 | batch_size=128\n",
            "[PCA] var_exp≈0.9502 | dim: 12288 → 315 | whiten=False\n",
            "[Model] MLP_relu_hs[512, 256]_do0.4_PCA95 | optimizer=Adam(lr=0.0001) | dropout=0.4 | activation=relu\n",
            "[MLP_relu_hs[512, 256]_do0.4_PCA95] Ep 01/30 | Train loss 2.7912 acc 0.092 | Val loss 2.3132 acc 0.133 F1(macro) 0.105\n",
            "[MLP_relu_hs[512, 256]_do0.4_PCA95] Ep 02/30 | Train loss 2.5601 acc 0.128 | Val loss 2.2427 acc 0.169 F1(macro) 0.121\n",
            "[MLP_relu_hs[512, 256]_do0.4_PCA95] Ep 03/30 | Train loss 2.4369 acc 0.138 | Val loss 2.1992 acc 0.217 F1(macro) 0.158\n",
            "[MLP_relu_hs[512, 256]_do0.4_PCA95] Ep 04/30 | Train loss 2.3498 acc 0.179 | Val loss 2.1590 acc 0.265 F1(macro) 0.218\n",
            "[MLP_relu_hs[512, 256]_do0.4_PCA95] Ep 05/30 | Train loss 2.3476 acc 0.177 | Val loss 2.1195 acc 0.253 F1(macro) 0.215\n",
            "[MLP_relu_hs[512, 256]_do0.4_PCA95] Ep 06/30 | Train loss 2.2203 acc 0.212 | Val loss 2.0855 acc 0.301 F1(macro) 0.264\n",
            "[MLP_relu_hs[512, 256]_do0.4_PCA95] Ep 07/30 | Train loss 2.1706 acc 0.238 | Val loss 2.0553 acc 0.277 F1(macro) 0.230\n",
            "[MLP_relu_hs[512, 256]_do0.4_PCA95] Ep 08/30 | Train loss 2.1586 acc 0.232 | Val loss 2.0289 acc 0.265 F1(macro) 0.229\n",
            "[MLP_relu_hs[512, 256]_do0.4_PCA95] Ep 09/30 | Train loss 2.0619 acc 0.290 | Val loss 2.0068 acc 0.265 F1(macro) 0.229\n",
            "[MLP_relu_hs[512, 256]_do0.4_PCA95] Ep 10/30 | Train loss 2.0104 acc 0.296 | Val loss 1.9866 acc 0.265 F1(macro) 0.230\n",
            "[MLP_relu_hs[512, 256]_do0.4_PCA95] Ep 11/30 | Train loss 1.9697 acc 0.304 | Val loss 1.9661 acc 0.277 F1(macro) 0.239\n",
            "[MLP_relu_hs[512, 256]_do0.4_PCA95] Ep 12/30 | Train loss 1.9242 acc 0.353 | Val loss 1.9466 acc 0.301 F1(macro) 0.271\n",
            "[MLP_relu_hs[512, 256]_do0.4_PCA95] Ep 13/30 | Train loss 1.8974 acc 0.347 | Val loss 1.9275 acc 0.337 F1(macro) 0.314\n",
            "[MLP_relu_hs[512, 256]_do0.4_PCA95] Ep 14/30 | Train loss 1.8266 acc 0.370 | Val loss 1.9092 acc 0.373 F1(macro) 0.338\n",
            "[MLP_relu_hs[512, 256]_do0.4_PCA95] Ep 15/30 | Train loss 1.8156 acc 0.374 | Val loss 1.8912 acc 0.373 F1(macro) 0.347\n",
            "[MLP_relu_hs[512, 256]_do0.4_PCA95] Ep 16/30 | Train loss 1.7520 acc 0.403 | Val loss 1.8723 acc 0.373 F1(macro) 0.339\n",
            "[MLP_relu_hs[512, 256]_do0.4_PCA95] Ep 17/30 | Train loss 1.7875 acc 0.383 | Val loss 1.8539 acc 0.361 F1(macro) 0.316\n",
            "[MLP_relu_hs[512, 256]_do0.4_PCA95] Ep 18/30 | Train loss 1.7204 acc 0.389 | Val loss 1.8357 acc 0.373 F1(macro) 0.346\n",
            "[MLP_relu_hs[512, 256]_do0.4_PCA95] Ep 19/30 | Train loss 1.6724 acc 0.421 | Val loss 1.8184 acc 0.386 F1(macro) 0.354\n",
            "[MLP_relu_hs[512, 256]_do0.4_PCA95] Ep 20/30 | Train loss 1.6314 acc 0.454 | Val loss 1.8031 acc 0.373 F1(macro) 0.348\n",
            "[MLP_relu_hs[512, 256]_do0.4_PCA95] Ep 21/30 | Train loss 1.6386 acc 0.444 | Val loss 1.7894 acc 0.361 F1(macro) 0.338\n",
            "[MLP_relu_hs[512, 256]_do0.4_PCA95] Ep 22/30 | Train loss 1.6106 acc 0.457 | Val loss 1.7758 acc 0.373 F1(macro) 0.346\n",
            "[MLP_relu_hs[512, 256]_do0.4_PCA95] Ep 23/30 | Train loss 1.5423 acc 0.481 | Val loss 1.7652 acc 0.410 F1(macro) 0.386\n",
            "[MLP_relu_hs[512, 256]_do0.4_PCA95] Ep 24/30 | Train loss 1.5254 acc 0.493 | Val loss 1.7547 acc 0.410 F1(macro) 0.386\n",
            "[MLP_relu_hs[512, 256]_do0.4_PCA95] Ep 25/30 | Train loss 1.4894 acc 0.481 | Val loss 1.7425 acc 0.434 F1(macro) 0.413\n",
            "[MLP_relu_hs[512, 256]_do0.4_PCA95] Ep 26/30 | Train loss 1.4871 acc 0.490 | Val loss 1.7224 acc 0.422 F1(macro) 0.401\n",
            "[MLP_relu_hs[512, 256]_do0.4_PCA95] Ep 27/30 | Train loss 1.4479 acc 0.510 | Val loss 1.7021 acc 0.434 F1(macro) 0.423\n",
            "[MLP_relu_hs[512, 256]_do0.4_PCA95] Ep 28/30 | Train loss 1.4063 acc 0.556 | Val loss 1.6832 acc 0.410 F1(macro) 0.409\n",
            "[MLP_relu_hs[512, 256]_do0.4_PCA95] Ep 29/30 | Train loss 1.4003 acc 0.528 | Val loss 1.6671 acc 0.434 F1(macro) 0.428\n",
            "[MLP_relu_hs[512, 256]_do0.4_PCA95] Ep 30/30 | Train loss 1.3661 acc 0.555 | Val loss 1.6577 acc 0.458 F1(macro) 0.457\n",
            "[Tiempo] ~0.05s/epoch | best Val F1(macro)=0.457\n",
            "[Test] acc=0.488 | F1(macro)=0.447 | F1(weighted)=0.446\n",
            "\n",
            "MLP_relu_hs[512, 256]_do0.4_PCA95 - Confusion Matrix — Matriz de confusión\n",
            "          pred_001  pred_002  pred_003  pred_004  pred_005  pred_006  pred_007  pred_008  pred_009  pred_010\n",
            "true_001         4         0         0         0         0         0         0         0         0         4\n",
            "true_002         0         7         0         0         1         0         1         0         0         1\n",
            "true_003         0         3         0         0         0         1         1         1         0         0\n",
            "true_004         1         2         0         2         1         1         1         0         0         1\n",
            "true_005         0         1         0         0         3         2         1         0         0         2\n",
            "true_006         0         1         0         2         0         7         0         0         0         0\n",
            "true_007         1         0         0         0         0         0         6         0         1         1\n",
            "true_008         0         0         0         0         0         0         0         5         0         0\n",
            "true_009         0         1         0         2         0         4         0         1         1         0\n",
            "true_010         0         0         0         1         1         0         0         0         1         6\n",
            "\n",
            "[Classification report]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         001      0.667     0.500     0.571         8\n",
            "         002      0.467     0.700     0.560        10\n",
            "         003      0.000     0.000     0.000         6\n",
            "         004      0.286     0.222     0.250         9\n",
            "         005      0.500     0.333     0.400         9\n",
            "         006      0.467     0.700     0.560        10\n",
            "         007      0.600     0.667     0.632         9\n",
            "         008      0.714     1.000     0.833         5\n",
            "         009      0.333     0.111     0.167         9\n",
            "         010      0.400     0.667     0.500         9\n",
            "\n",
            "    accuracy                          0.488        84\n",
            "   macro avg      0.443     0.490     0.447        84\n",
            "weighted avg      0.444     0.488     0.446        84\n",
            "\n",
            "\n",
            "========================================================================\n",
            "RUN | model=mlp | img=64 | bs=128 | epochs=30 | opt=adam | lr=0.005 | aug=True | act=relu | hs=[512, 256] | do=0.2 | use_pca=True | pca_var=0.95 | whiten=True\n",
            "========================================================================\n",
            "[Device] cpu | CUDA avail=False\n",
            "[Data] imgs=832 | clases=10 | img_size=64 | augment=True | use_pca=True\n",
            "[Split] train=665 | val=83 | test=84 | batch_size=128\n",
            "[PCA] var_exp≈0.9502 | dim: 12288 → 315 | whiten=True\n",
            "[Model] MLP_relu_hs[512, 256]_do0.2_PCA95W | optimizer=Adam(lr=0.005) | dropout=0.2 | activation=relu\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95W] Ep 01/30 | Train loss 2.3167 acc 0.108 | Val loss 2.1593 acc 0.386 F1(macro) 0.328\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95W] Ep 02/30 | Train loss 1.6234 acc 0.666 | Val loss 1.7440 acc 0.361 F1(macro) 0.340\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95W] Ep 03/30 | Train loss 0.5713 acc 0.872 | Val loss 1.6820 acc 0.386 F1(macro) 0.393\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95W] Ep 04/30 | Train loss 0.1081 acc 0.985 | Val loss 2.0262 acc 0.470 F1(macro) 0.452\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95W] Ep 05/30 | Train loss 0.0563 acc 0.985 | Val loss 2.4028 acc 0.446 F1(macro) 0.427\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95W] Ep 06/30 | Train loss 0.0135 acc 0.998 | Val loss 2.8826 acc 0.398 F1(macro) 0.388\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95W] Ep 07/30 | Train loss 0.0101 acc 0.998 | Val loss 3.0717 acc 0.398 F1(macro) 0.395\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95W] Ep 08/30 | Train loss 0.0076 acc 0.998 | Val loss 3.2502 acc 0.398 F1(macro) 0.391\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95W] Ep 09/30 | Train loss 0.0093 acc 0.997 | Val loss 3.6167 acc 0.434 F1(macro) 0.419\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95W] Ep 10/30 | Train loss 0.0052 acc 0.998 | Val loss 3.5019 acc 0.373 F1(macro) 0.364\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95W] Ep 11/30 | Train loss 0.0081 acc 0.995 | Val loss 3.5554 acc 0.373 F1(macro) 0.359\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95W] Ep 12/30 | Train loss 0.0043 acc 1.000 | Val loss 3.6219 acc 0.398 F1(macro) 0.387\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95W] Ep 13/30 | Train loss 0.0027 acc 1.000 | Val loss 3.7081 acc 0.398 F1(macro) 0.387\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95W] Ep 14/30 | Train loss 0.0023 acc 1.000 | Val loss 3.7282 acc 0.398 F1(macro) 0.390\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95W] Ep 15/30 | Train loss 0.0032 acc 1.000 | Val loss 3.7485 acc 0.410 F1(macro) 0.400\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95W] Ep 16/30 | Train loss 0.0022 acc 1.000 | Val loss 3.7529 acc 0.434 F1(macro) 0.424\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95W] Ep 17/30 | Train loss 0.0012 acc 1.000 | Val loss 3.7996 acc 0.446 F1(macro) 0.446\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95W] Ep 18/30 | Train loss 0.0023 acc 1.000 | Val loss 3.8497 acc 0.458 F1(macro) 0.452\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95W] Ep 19/30 | Train loss 0.0057 acc 0.995 | Val loss 3.9565 acc 0.422 F1(macro) 0.410\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95W] Ep 20/30 | Train loss 0.0114 acc 0.995 | Val loss 4.1181 acc 0.434 F1(macro) 0.422\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95W] Ep 21/30 | Train loss 0.0022 acc 1.000 | Val loss 4.2397 acc 0.434 F1(macro) 0.420\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95W] Ep 22/30 | Train loss 0.0075 acc 0.998 | Val loss 4.1475 acc 0.422 F1(macro) 0.422\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95W] Ep 23/30 | Train loss 0.0039 acc 0.998 | Val loss 4.2544 acc 0.422 F1(macro) 0.439\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95W] Ep 24/30 | Train loss 0.0109 acc 0.998 | Val loss 4.4541 acc 0.410 F1(macro) 0.421\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95W] Ep 25/30 | Train loss 0.0056 acc 0.997 | Val loss 4.4289 acc 0.410 F1(macro) 0.426\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95W] Ep 26/30 | Train loss 0.0056 acc 0.998 | Val loss 4.7385 acc 0.446 F1(macro) 0.450\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95W] Ep 27/30 | Train loss 0.0218 acc 0.988 | Val loss 4.8055 acc 0.386 F1(macro) 0.402\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95W] Ep 28/30 | Train loss 0.0728 acc 0.976 | Val loss 5.0271 acc 0.410 F1(macro) 0.409\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95W] Ep 29/30 | Train loss 0.1864 acc 0.965 | Val loss 5.7977 acc 0.373 F1(macro) 0.396\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95W] Ep 30/30 | Train loss 0.1765 acc 0.950 | Val loss 6.3846 acc 0.386 F1(macro) 0.388\n",
            "[Tiempo] ~0.04s/epoch | best Val F1(macro)=0.452\n",
            "[Test] acc=0.536 | F1(macro)=0.528 | F1(weighted)=0.518\n",
            "\n",
            "MLP_relu_hs[512, 256]_do0.2_PCA95W - Confusion Matrix — Matriz de confusión\n",
            "          pred_001  pred_002  pred_003  pred_004  pred_005  pred_006  pred_007  pred_008  pred_009  pred_010\n",
            "true_001         3         0         2         0         0         0         0         0         0         3\n",
            "true_002         0         8         0         1         1         0         0         0         0         0\n",
            "true_003         0         0         3         0         1         1         0         0         1         0\n",
            "true_004         1         1         2         2         0         1         0         0         1         1\n",
            "true_005         0         0         1         0         6         0         0         0         0         2\n",
            "true_006         0         1         0         0         0         7         0         0         1         1\n",
            "true_007         1         1         0         0         1         1         4         0         0         1\n",
            "true_008         0         0         0         0         0         0         0         4         0         1\n",
            "true_009         0         0         1         0         0         6         1         0         1         0\n",
            "true_010         0         1         0         1         0         0         0         0         0         7\n",
            "\n",
            "[Classification report]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         001      0.600     0.375     0.462         8\n",
            "         002      0.667     0.800     0.727        10\n",
            "         003      0.333     0.500     0.400         6\n",
            "         004      0.500     0.222     0.308         9\n",
            "         005      0.667     0.667     0.667         9\n",
            "         006      0.438     0.700     0.538        10\n",
            "         007      0.800     0.444     0.571         9\n",
            "         008      1.000     0.800     0.889         5\n",
            "         009      0.250     0.111     0.154         9\n",
            "         010      0.438     0.778     0.560         9\n",
            "\n",
            "    accuracy                          0.536        84\n",
            "   macro avg      0.569     0.540     0.528        84\n",
            "weighted avg      0.556     0.536     0.518        84\n",
            "\n",
            "\n",
            "========================================================================\n",
            "RUN | model=mlp | img=64 | bs=128 | epochs=30 | opt=adam | lr=0.0003 | aug=True | act=relu | hs=[512, 256] | do=0.2 | use_pca=True | pca_var=0.95 | whiten=True\n",
            "========================================================================\n",
            "[Device] cpu | CUDA avail=False\n",
            "[Data] imgs=832 | clases=10 | img_size=64 | augment=True | use_pca=True\n",
            "[Split] train=665 | val=83 | test=84 | batch_size=128\n",
            "[PCA] var_exp≈0.9502 | dim: 12288 → 315 | whiten=True\n",
            "[Model] MLP_relu_hs[512, 256]_do0.2_PCA95W | optimizer=Adam(lr=0.0003) | dropout=0.2 | activation=relu\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95W] Ep 01/30 | Train loss 2.3081 acc 0.098 | Val loss 2.2781 acc 0.133 F1(macro) 0.090\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95W] Ep 02/30 | Train loss 2.2548 acc 0.171 | Val loss 2.2644 acc 0.205 F1(macro) 0.136\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95W] Ep 03/30 | Train loss 2.2108 acc 0.295 | Val loss 2.2509 acc 0.181 F1(macro) 0.139\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95W] Ep 04/30 | Train loss 2.1739 acc 0.355 | Val loss 2.2354 acc 0.181 F1(macro) 0.136\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95W] Ep 05/30 | Train loss 2.1326 acc 0.420 | Val loss 2.2189 acc 0.181 F1(macro) 0.137\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95W] Ep 06/30 | Train loss 2.0874 acc 0.486 | Val loss 2.2009 acc 0.241 F1(macro) 0.184\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95W] Ep 07/30 | Train loss 2.0276 acc 0.561 | Val loss 2.1799 acc 0.277 F1(macro) 0.222\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95W] Ep 08/30 | Train loss 1.9646 acc 0.589 | Val loss 2.1556 acc 0.313 F1(macro) 0.274\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95W] Ep 09/30 | Train loss 1.8833 acc 0.660 | Val loss 2.1273 acc 0.361 F1(macro) 0.345\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95W] Ep 10/30 | Train loss 1.7999 acc 0.711 | Val loss 2.0933 acc 0.373 F1(macro) 0.343\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95W] Ep 11/30 | Train loss 1.6956 acc 0.779 | Val loss 2.0546 acc 0.386 F1(macro) 0.352\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95W] Ep 12/30 | Train loss 1.5778 acc 0.835 | Val loss 2.0083 acc 0.410 F1(macro) 0.366\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95W] Ep 13/30 | Train loss 1.4444 acc 0.883 | Val loss 1.9570 acc 0.422 F1(macro) 0.375\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95W] Ep 14/30 | Train loss 1.3004 acc 0.904 | Val loss 1.9030 acc 0.470 F1(macro) 0.445\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95W] Ep 15/30 | Train loss 1.1652 acc 0.928 | Val loss 1.8409 acc 0.458 F1(macro) 0.432\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95W] Ep 16/30 | Train loss 1.0099 acc 0.926 | Val loss 1.7836 acc 0.470 F1(macro) 0.446\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95W] Ep 17/30 | Train loss 0.8541 acc 0.955 | Val loss 1.7337 acc 0.494 F1(macro) 0.467\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95W] Ep 18/30 | Train loss 0.7169 acc 0.967 | Val loss 1.6896 acc 0.494 F1(macro) 0.471\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95W] Ep 19/30 | Train loss 0.6184 acc 0.977 | Val loss 1.6455 acc 0.446 F1(macro) 0.452\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95W] Ep 20/30 | Train loss 0.5134 acc 0.977 | Val loss 1.6150 acc 0.434 F1(macro) 0.445\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95W] Ep 21/30 | Train loss 0.4163 acc 0.994 | Val loss 1.5973 acc 0.434 F1(macro) 0.431\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95W] Ep 22/30 | Train loss 0.3577 acc 0.988 | Val loss 1.5792 acc 0.458 F1(macro) 0.444\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95W] Ep 23/30 | Train loss 0.2945 acc 0.994 | Val loss 1.5689 acc 0.470 F1(macro) 0.452\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95W] Ep 24/30 | Train loss 0.2488 acc 0.994 | Val loss 1.5544 acc 0.470 F1(macro) 0.468\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95W] Ep 25/30 | Train loss 0.2081 acc 0.994 | Val loss 1.5495 acc 0.458 F1(macro) 0.452\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95W] Ep 26/30 | Train loss 0.1786 acc 0.995 | Val loss 1.5445 acc 0.458 F1(macro) 0.452\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95W] Ep 27/30 | Train loss 0.1499 acc 0.998 | Val loss 1.5425 acc 0.446 F1(macro) 0.449\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95W] Ep 28/30 | Train loss 0.1311 acc 1.000 | Val loss 1.5430 acc 0.434 F1(macro) 0.435\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95W] Ep 29/30 | Train loss 0.1180 acc 1.000 | Val loss 1.5476 acc 0.434 F1(macro) 0.435\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95W] Ep 30/30 | Train loss 0.1022 acc 1.000 | Val loss 1.5520 acc 0.434 F1(macro) 0.434\n",
            "[Tiempo] ~0.05s/epoch | best Val F1(macro)=0.471\n",
            "[Test] acc=0.536 | F1(macro)=0.519 | F1(weighted)=0.520\n",
            "\n",
            "MLP_relu_hs[512, 256]_do0.2_PCA95W - Confusion Matrix — Matriz de confusión\n",
            "          pred_001  pred_002  pred_003  pred_004  pred_005  pred_006  pred_007  pred_008  pred_009  pred_010\n",
            "true_001         6         0         0         1         0         0         0         0         0         1\n",
            "true_002         1         8         0         0         0         0         1         0         0         0\n",
            "true_003         0         1         1         0         0         1         1         0         1         1\n",
            "true_004         2         2         1         2         0         0         1         0         1         0\n",
            "true_005         1         0         0         0         5         2         0         0         0         1\n",
            "true_006         1         1         0         1         0         6         1         0         0         0\n",
            "true_007         1         0         1         0         0         0         7         0         0         0\n",
            "true_008         0         0         0         0         1         0         0         3         0         1\n",
            "true_009         0         0         0         0         1         5         0         0         3         0\n",
            "true_010         2         0         0         1         1         0         0         0         1         4\n",
            "\n",
            "[Classification report]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         001      0.429     0.750     0.545         8\n",
            "         002      0.667     0.800     0.727        10\n",
            "         003      0.333     0.167     0.222         6\n",
            "         004      0.400     0.222     0.286         9\n",
            "         005      0.625     0.556     0.588         9\n",
            "         006      0.429     0.600     0.500        10\n",
            "         007      0.636     0.778     0.700         9\n",
            "         008      1.000     0.600     0.750         5\n",
            "         009      0.500     0.333     0.400         9\n",
            "         010      0.500     0.444     0.471         9\n",
            "\n",
            "    accuracy                          0.536        84\n",
            "   macro avg      0.552     0.525     0.519        84\n",
            "weighted avg      0.540     0.536     0.520        84\n",
            "\n",
            "\n",
            "========================================================================\n",
            "RUN | model=mlp | img=64 | bs=128 | epochs=30 | opt=adam | lr=0.0001 | aug=True | act=relu | hs=[512, 256] | do=0.2 | use_pca=True | pca_var=0.95 | whiten=True\n",
            "========================================================================\n",
            "[Device] cpu | CUDA avail=False\n",
            "[Data] imgs=832 | clases=10 | img_size=64 | augment=True | use_pca=True\n",
            "[Split] train=665 | val=83 | test=84 | batch_size=128\n",
            "[PCA] var_exp≈0.9502 | dim: 12288 → 315 | whiten=True\n",
            "[Model] MLP_relu_hs[512, 256]_do0.2_PCA95W | optimizer=Adam(lr=0.0001) | dropout=0.2 | activation=relu\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95W] Ep 01/30 | Train loss 2.3112 acc 0.098 | Val loss 2.2907 acc 0.133 F1(macro) 0.082\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95W] Ep 02/30 | Train loss 2.2930 acc 0.122 | Val loss 2.2850 acc 0.120 F1(macro) 0.073\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95W] Ep 03/30 | Train loss 2.2719 acc 0.144 | Val loss 2.2797 acc 0.133 F1(macro) 0.089\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95W] Ep 04/30 | Train loss 2.2592 acc 0.155 | Val loss 2.2746 acc 0.169 F1(macro) 0.120\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95W] Ep 05/30 | Train loss 2.2473 acc 0.191 | Val loss 2.2699 acc 0.181 F1(macro) 0.128\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95W] Ep 06/30 | Train loss 2.2385 acc 0.203 | Val loss 2.2654 acc 0.169 F1(macro) 0.113\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95W] Ep 07/30 | Train loss 2.2239 acc 0.242 | Val loss 2.2609 acc 0.181 F1(macro) 0.124\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95W] Ep 08/30 | Train loss 2.2102 acc 0.272 | Val loss 2.2563 acc 0.169 F1(macro) 0.114\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95W] Ep 09/30 | Train loss 2.1953 acc 0.308 | Val loss 2.2517 acc 0.169 F1(macro) 0.126\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95W] Ep 10/30 | Train loss 2.1835 acc 0.323 | Val loss 2.2470 acc 0.157 F1(macro) 0.123\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95W] Ep 11/30 | Train loss 2.1650 acc 0.356 | Val loss 2.2421 acc 0.193 F1(macro) 0.160\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95W] Ep 12/30 | Train loss 2.1520 acc 0.380 | Val loss 2.2368 acc 0.217 F1(macro) 0.175\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95W] Ep 13/30 | Train loss 2.1365 acc 0.402 | Val loss 2.2313 acc 0.217 F1(macro) 0.170\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95W] Ep 14/30 | Train loss 2.1153 acc 0.436 | Val loss 2.2255 acc 0.217 F1(macro) 0.161\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95W] Ep 15/30 | Train loss 2.1054 acc 0.453 | Val loss 2.2185 acc 0.229 F1(macro) 0.168\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95W] Ep 16/30 | Train loss 2.0856 acc 0.489 | Val loss 2.2115 acc 0.253 F1(macro) 0.184\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95W] Ep 17/30 | Train loss 2.0615 acc 0.528 | Val loss 2.2045 acc 0.265 F1(macro) 0.202\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95W] Ep 18/30 | Train loss 2.0393 acc 0.562 | Val loss 2.1971 acc 0.253 F1(macro) 0.203\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95W] Ep 19/30 | Train loss 2.0243 acc 0.567 | Val loss 2.1887 acc 0.241 F1(macro) 0.198\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95W] Ep 20/30 | Train loss 2.0011 acc 0.588 | Val loss 2.1799 acc 0.229 F1(macro) 0.193\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95W] Ep 21/30 | Train loss 1.9701 acc 0.626 | Val loss 2.1715 acc 0.253 F1(macro) 0.225\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95W] Ep 22/30 | Train loss 1.9491 acc 0.620 | Val loss 2.1624 acc 0.325 F1(macro) 0.305\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95W] Ep 23/30 | Train loss 1.9231 acc 0.660 | Val loss 2.1531 acc 0.313 F1(macro) 0.283\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95W] Ep 24/30 | Train loss 1.8895 acc 0.683 | Val loss 2.1428 acc 0.337 F1(macro) 0.320\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95W] Ep 25/30 | Train loss 1.8598 acc 0.708 | Val loss 2.1317 acc 0.325 F1(macro) 0.302\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95W] Ep 26/30 | Train loss 1.8220 acc 0.726 | Val loss 2.1193 acc 0.349 F1(macro) 0.334\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95W] Ep 27/30 | Train loss 1.7819 acc 0.732 | Val loss 2.1059 acc 0.386 F1(macro) 0.364\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95W] Ep 28/30 | Train loss 1.7532 acc 0.731 | Val loss 2.0921 acc 0.398 F1(macro) 0.375\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95W] Ep 29/30 | Train loss 1.7250 acc 0.767 | Val loss 2.0773 acc 0.422 F1(macro) 0.396\n",
            "[MLP_relu_hs[512, 256]_do0.2_PCA95W] Ep 30/30 | Train loss 1.6757 acc 0.802 | Val loss 2.0624 acc 0.386 F1(macro) 0.366\n",
            "[Tiempo] ~0.04s/epoch | best Val F1(macro)=0.396\n",
            "[Test] acc=0.440 | F1(macro)=0.355 | F1(weighted)=0.387\n",
            "\n",
            "MLP_relu_hs[512, 256]_do0.2_PCA95W - Confusion Matrix — Matriz de confusión\n",
            "          pred_001  pred_002  pred_003  pred_004  pred_005  pred_006  pred_007  pred_008  pred_009  pred_010\n",
            "true_001         5         0         0         0         0         0         0         0         1         2\n",
            "true_002         0         8         0         0         0         0         2         0         0         0\n",
            "true_003         0         2         0         0         0         1         2         0         1         0\n",
            "true_004         2         2         0         2         0         0         2         0         1         0\n",
            "true_005         1         0         0         0         4         3         0         0         0         1\n",
            "true_006         0         1         0         0         0         8         1         0         0         0\n",
            "true_007         0         2         0         0         0         1         6         0         0         0\n",
            "true_008         0         2         0         0         1         1         0         0         0         1\n",
            "true_009         0         0         0         1         0         5         0         0         3         0\n",
            "true_010         1         1         0         2         1         1         1         0         1         1\n",
            "\n",
            "[Classification report]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         001      0.556     0.625     0.588         8\n",
            "         002      0.444     0.800     0.571        10\n",
            "         003      0.000     0.000     0.000         6\n",
            "         004      0.400     0.222     0.286         9\n",
            "         005      0.667     0.444     0.533         9\n",
            "         006      0.400     0.800     0.533        10\n",
            "         007      0.429     0.667     0.522         9\n",
            "         008      0.000     0.000     0.000         5\n",
            "         009      0.429     0.333     0.375         9\n",
            "         010      0.200     0.111     0.143         9\n",
            "\n",
            "    accuracy                          0.440        84\n",
            "   macro avg      0.352     0.400     0.355        84\n",
            "weighted avg      0.381     0.440     0.387        84\n",
            "\n",
            "\n",
            "========================================================================\n",
            "RUN | model=mlp | img=64 | bs=128 | epochs=30 | opt=adam | lr=0.005 | aug=True | act=relu | hs=[512, 256] | do=0.4 | use_pca=True | pca_var=0.95 | whiten=True\n",
            "========================================================================\n",
            "[Device] cpu | CUDA avail=False\n",
            "[Data] imgs=832 | clases=10 | img_size=64 | augment=True | use_pca=True\n",
            "[Split] train=665 | val=83 | test=84 | batch_size=128\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================================\n",
        "# 7. Visualización de artefactos guardados (curvas + reports + CM tabular)\n",
        "# ========================================================\n",
        "import os, glob\n",
        "from IPython.display import Image, display\n",
        "import pandas as pd\n",
        "\n",
        "print(\"Imágenes guardadas en outputs/:\")\n",
        "imgs = sorted(glob.glob(\"outputs/*.png\"))\n",
        "if imgs:\n",
        "    for img in imgs:\n",
        "        print(\" -\", img)\n",
        "        display(Image(filename=img))\n",
        "else:\n",
        "    print(\" (no hay PNGs — ejecuta la Celda 6 con save_artifacts=True en los mejores)\")\n",
        "\n",
        "def show_report(prefix):\n",
        "    csv_path = f\"outputs/{prefix}_classification_report.csv\"\n",
        "    if os.path.exists(csv_path):\n",
        "        print(\"\\nReporte (classification_report):\", csv_path)\n",
        "        df = pd.read_csv(csv_path, index_col=0)\n",
        "        display(df)\n",
        "    else:\n",
        "        print(\"\\nNo se encontró:\", csv_path)\n",
        "\n",
        "def show_confusion(prefix):\n",
        "    raw_path  = f\"outputs/{prefix}_confusion_matrix.csv\"\n",
        "    norm_path = f\"outputs/{prefix}_confusion_matrix_norm.csv\"\n",
        "\n",
        "    if os.path.exists(raw_path):\n",
        "        print(\"\\nMatriz de confusión (cruda):\", raw_path)\n",
        "        df_raw = pd.read_csv(raw_path, index_col=0)\n",
        "        display(df_raw)\n",
        "    else:\n",
        "        print(\"\\nNo se encontró:\", raw_path)\n",
        "\n",
        "    if os.path.exists(norm_path):\n",
        "        print(\"\\nMatriz de confusión (normalizada por fila):\", norm_path)\n",
        "        df_norm = pd.read_csv(norm_path, index_col=0)\n",
        "        display(df_norm)\n",
        "    else:\n",
        "        print(\"No se encontró:\", norm_path)\n",
        "\n",
        "# Usa los prefijos obtenidos en la celda 6:\n",
        "print(\"\\n=== MLP (mejor) ===\")\n",
        "show_report(best_title_mlp)\n",
        "show_confusion(best_title_mlp)\n",
        "\n",
        "print(\"\\n=== CNN (mejor) ===\")\n",
        "show_report(best_title_cnn)\n",
        "show_confusion(best_title_cnn)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jpoq_bn8vVXd",
        "outputId": "9ddd28b8-61ad-48ba-a3ae-42abfe6fb13d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imágenes guardadas en outputs/:\n",
            " - outputs/MLP_sigmoid_hs[512, 256]_do0.4_PCA95_acc.png\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "[IMAGEN OMITIDA POR SU LONGITUD]",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " - outputs/MLP_sigmoid_hs[512, 256]_do0.4_PCA95_loss.png\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "[IMAGEN OMITIDA POR SU LONGITUD]",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " - outputs/SimpleCNN_acc.png\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "[IMAGEN OMITIDA POR SU LONGITUD]",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " - outputs/SimpleCNN_loss.png\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "[IMAGEN OMITIDA POR SU LONGITUD]",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== MLP (mejor) ===\n",
            "\n",
            "Reporte (classification_report): outputs/MLP_sigmoid_hs[512, 256]_do0.4_PCA95_classification_report.csv\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                001   002       003       004       005        006       007  \\\n",
              "precision  1.000000   0.6  1.000000  0.571429  0.666667   0.636364  0.700000   \n",
              "recall     0.625000   0.6  0.166667  0.444444  0.666667   0.700000  0.777778   \n",
              "f1-score   0.769231   0.6  0.285714  0.500000  0.666667   0.666667  0.736842   \n",
              "support    8.000000  10.0  6.000000  9.000000  9.000000  10.000000  9.000000   \n",
              "\n",
              "                008       009       010  accuracy  macro avg  weighted avg  \n",
              "precision  0.714286  0.500000  0.437500  0.619048   0.682624      0.664469  \n",
              "recall     1.000000  0.444444  0.777778  0.619048   0.620278      0.619048  \n",
              "f1-score   0.833333  0.470588  0.560000  0.619048   0.608904      0.608433  \n",
              "support    5.000000  9.000000  9.000000  0.619048  84.000000     84.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bc45426a-fd7e-434f-b83c-56c81dbc6c7a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>001</th>\n",
              "      <th>002</th>\n",
              "      <th>003</th>\n",
              "      <th>004</th>\n",
              "      <th>005</th>\n",
              "      <th>006</th>\n",
              "      <th>007</th>\n",
              "      <th>008</th>\n",
              "      <th>009</th>\n",
              "      <th>010</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>macro avg</th>\n",
              "      <th>weighted avg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>precision</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.6</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.636364</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.437500</td>\n",
              "      <td>0.619048</td>\n",
              "      <td>0.682624</td>\n",
              "      <td>0.664469</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>recall</th>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.444444</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>0.777778</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.444444</td>\n",
              "      <td>0.777778</td>\n",
              "      <td>0.619048</td>\n",
              "      <td>0.620278</td>\n",
              "      <td>0.619048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f1-score</th>\n",
              "      <td>0.769231</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.736842</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.470588</td>\n",
              "      <td>0.560000</td>\n",
              "      <td>0.619048</td>\n",
              "      <td>0.608904</td>\n",
              "      <td>0.608433</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>support</th>\n",
              "      <td>8.000000</td>\n",
              "      <td>10.0</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>0.619048</td>\n",
              "      <td>84.000000</td>\n",
              "      <td>84.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bc45426a-fd7e-434f-b83c-56c81dbc6c7a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bc45426a-fd7e-434f-b83c-56c81dbc6c7a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bc45426a-fd7e-434f-b83c-56c81dbc6c7a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-08f4bb85-1fef-482a-a461-b2fd0622b158\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-08f4bb85-1fef-482a-a461-b2fd0622b158')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-08f4bb85-1fef-482a-a461-b2fd0622b158 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"show_confusion(best_title_cnn)\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"001\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.604272125100316,\n        \"min\": 0.625,\n        \"max\": 8.0,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.625,\n          8.0,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"002\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.7,\n        \"min\": 0.6,\n        \"max\": 10.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          10.0,\n          0.6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"003\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.7823799744095816,\n        \"min\": 0.1666666666666666,\n        \"max\": 6.0,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.1666666666666666,\n          6.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"004\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.247672506010434,\n        \"min\": 0.4444444444444444,\n        \"max\": 9.0,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.4444444444444444,\n          9.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"005\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.166666666666667,\n        \"min\": 0.6666666666666666,\n        \"max\": 9.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          9.0,\n          0.6666666666666666\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"006\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.666233992142002,\n        \"min\": 0.6363636363636364,\n        \"max\": 10.0,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.7,\n          10.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"007\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.131018832339036,\n        \"min\": 0.7,\n        \"max\": 9.0,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.7777777777777778,\n          9.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"008\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.078702335920308,\n        \"min\": 0.7142857142857143,\n        \"max\": 5.0,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          1.0,\n          5.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"009\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.2642216062406675,\n        \"min\": 0.4444444444444444,\n        \"max\": 9.0,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.4444444444444444,\n          9.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"010\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.206474839440464,\n        \"min\": 0.4375,\n        \"max\": 9.0,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.7777777777777778,\n          9.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.6190476190476191,\n        \"max\": 0.6190476190476191,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.6190476190476191\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"macro avg\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 41.68137818993255,\n        \"min\": 0.6089042062168998,\n        \"max\": 84.0,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.6202777777777778\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"weighted avg\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 41.68468216351481,\n        \"min\": 0.6084325984104842,\n        \"max\": 84.0,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.6190476190476191\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Matriz de confusión (cruda): outputs/MLP_sigmoid_hs[512, 256]_do0.4_PCA95_confusion_matrix.csv\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "          pred_001  pred_002  pred_003  pred_004  pred_005  pred_006  \\\n",
              "true_001         5         0         0         0         0         0   \n",
              "true_002         0         6         0         1         1         0   \n",
              "true_003         0         1         1         0         1         1   \n",
              "true_004         0         1         0         4         1         0   \n",
              "true_005         0         0         0         0         6         0   \n",
              "true_006         0         0         0         1         0         7   \n",
              "true_007         0         1         0         0         0         0   \n",
              "true_008         0         0         0         0         0         0   \n",
              "true_009         0         1         0         0         0         3   \n",
              "true_010         0         0         0         1         0         0   \n",
              "\n",
              "          pred_007  pred_008  pred_009  pred_010  \n",
              "true_001         0         0         0         3  \n",
              "true_002         0         1         0         1  \n",
              "true_003         0         1         1         0  \n",
              "true_004         0         0         1         2  \n",
              "true_005         1         0         0         2  \n",
              "true_006         1         0         1         0  \n",
              "true_007         7         0         0         1  \n",
              "true_008         0         5         0         0  \n",
              "true_009         1         0         4         0  \n",
              "true_010         0         0         1         7  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0ef74bab-edc7-4090-841c-4d7084d60fca\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pred_001</th>\n",
              "      <th>pred_002</th>\n",
              "      <th>pred_003</th>\n",
              "      <th>pred_004</th>\n",
              "      <th>pred_005</th>\n",
              "      <th>pred_006</th>\n",
              "      <th>pred_007</th>\n",
              "      <th>pred_008</th>\n",
              "      <th>pred_009</th>\n",
              "      <th>pred_010</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>true_001</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>true_002</th>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>true_003</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>true_004</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>true_005</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>true_006</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>true_007</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>true_008</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>true_009</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>true_010</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0ef74bab-edc7-4090-841c-4d7084d60fca')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0ef74bab-edc7-4090-841c-4d7084d60fca button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0ef74bab-edc7-4090-841c-4d7084d60fca');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-327e7d58-5846-4e72-af78-e601b21ad282\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-327e7d58-5846-4e72-af78-e601b21ad282')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-327e7d58-5846-4e72-af78-e601b21ad282 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"show_confusion(best_title_cnn)\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"pred_001\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 5,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_002\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 6,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_003\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_004\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 4,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_005\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 6,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_006\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 0,\n        \"max\": 7,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          1,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_007\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 0,\n        \"max\": 7,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_008\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 5,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_009\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 4,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_010\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 0,\n        \"max\": 7,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1,\n          7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Matriz de confusión (normalizada por fila): outputs/MLP_sigmoid_hs[512, 256]_do0.4_PCA95_confusion_matrix_norm.csv\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "          pred_001  pred_002  pred_003  pred_004  pred_005  pred_006  \\\n",
              "true_001     0.625  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "true_002     0.000  0.600000  0.000000  0.100000  0.100000  0.000000   \n",
              "true_003     0.000  0.166667  0.166667  0.000000  0.166667  0.166667   \n",
              "true_004     0.000  0.111111  0.000000  0.444444  0.111111  0.000000   \n",
              "true_005     0.000  0.000000  0.000000  0.000000  0.666667  0.000000   \n",
              "true_006     0.000  0.000000  0.000000  0.100000  0.000000  0.700000   \n",
              "true_007     0.000  0.111111  0.000000  0.000000  0.000000  0.000000   \n",
              "true_008     0.000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "true_009     0.000  0.111111  0.000000  0.000000  0.000000  0.333333   \n",
              "true_010     0.000  0.000000  0.000000  0.111111  0.000000  0.000000   \n",
              "\n",
              "          pred_007  pred_008  pred_009  pred_010  \n",
              "true_001  0.000000  0.000000  0.000000  0.375000  \n",
              "true_002  0.000000  0.100000  0.000000  0.100000  \n",
              "true_003  0.000000  0.166667  0.166667  0.000000  \n",
              "true_004  0.000000  0.000000  0.111111  0.222222  \n",
              "true_005  0.111111  0.000000  0.000000  0.222222  \n",
              "true_006  0.100000  0.000000  0.100000  0.000000  \n",
              "true_007  0.777778  0.000000  0.000000  0.111111  \n",
              "true_008  0.000000  1.000000  0.000000  0.000000  \n",
              "true_009  0.111111  0.000000  0.444444  0.000000  \n",
              "true_010  0.000000  0.000000  0.111111  0.777778  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-39cf589d-4c7e-4c05-ad3f-be266a3477b5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pred_001</th>\n",
              "      <th>pred_002</th>\n",
              "      <th>pred_003</th>\n",
              "      <th>pred_004</th>\n",
              "      <th>pred_005</th>\n",
              "      <th>pred_006</th>\n",
              "      <th>pred_007</th>\n",
              "      <th>pred_008</th>\n",
              "      <th>pred_009</th>\n",
              "      <th>pred_010</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>true_001</th>\n",
              "      <td>0.625</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.375000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>true_002</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.100000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>true_003</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>true_004</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.444444</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.222222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>true_005</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.222222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>true_006</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>true_007</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.777778</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.111111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>true_008</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>true_009</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.444444</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>true_010</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.777778</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-39cf589d-4c7e-4c05-ad3f-be266a3477b5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-39cf589d-4c7e-4c05-ad3f-be266a3477b5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-39cf589d-4c7e-4c05-ad3f-be266a3477b5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-60aad618-7cc6-467b-aff9-9bea9e759e54\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-60aad618-7cc6-467b-aff9-9bea9e759e54')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-60aad618-7cc6-467b-aff9-9bea9e759e54 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"show_confusion(best_title_cnn)\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"pred_001\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.19764235376052372,\n        \"min\": 0.0,\n        \"max\": 0.625,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0,\n          0.625\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_002\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.18373134126036672,\n        \"min\": 0.0,\n        \"max\": 0.6,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.6,\n          0.111111\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_003\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05270473307872832,\n        \"min\": 0.0,\n        \"max\": 0.166667,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.166667,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_004\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1385599700308298,\n        \"min\": 0.0,\n        \"max\": 0.444444,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.1,\n          0.111111\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_005\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.20695729465453064,\n        \"min\": 0.0,\n        \"max\": 0.666667,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.1,\n          0.666667\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_006\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.23211318545964213,\n        \"min\": 0.0,\n        \"max\": 0.7,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.166667,\n          0.333333\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_007\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.24005321769372537,\n        \"min\": 0.0,\n        \"max\": 0.777778,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.111111,\n          0.777778\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_008\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3122202498949348,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.1,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_009\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.138599590258373,\n        \"min\": 0.0,\n        \"max\": 0.444444,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.166667,\n          0.444444\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_010\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.24487359149027163,\n        \"min\": 0.0,\n        \"max\": 0.777778,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.375,\n          0.1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== CNN (mejor) ===\n",
            "\n",
            "Reporte (classification_report): outputs/SimpleCNN_classification_report.csv\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                001   002       003       004       005        006       007  \\\n",
              "precision  1.000000   0.9  1.000000  0.500000  0.727273   0.857143  0.900000   \n",
              "recall     0.750000   0.9  0.500000  0.555556  0.888889   0.600000  1.000000   \n",
              "f1-score   0.857143   0.9  0.666667  0.526316  0.800000   0.705882  0.947368   \n",
              "support    8.000000  10.0  6.000000  9.000000  9.000000  10.000000  9.000000   \n",
              "\n",
              "           008       009       010  accuracy  macro avg  weighted avg  \n",
              "precision  1.0  0.727273  0.636364  0.785714   0.824805      0.809400  \n",
              "recall     1.0  0.888889  0.777778  0.785714   0.786111      0.785714  \n",
              "f1-score   1.0  0.800000  0.700000  0.785714   0.790338      0.784275  \n",
              "support    5.0  9.000000  9.000000  0.785714  84.000000     84.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d823878e-38ce-4cea-9555-98a372be2f33\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>001</th>\n",
              "      <th>002</th>\n",
              "      <th>003</th>\n",
              "      <th>004</th>\n",
              "      <th>005</th>\n",
              "      <th>006</th>\n",
              "      <th>007</th>\n",
              "      <th>008</th>\n",
              "      <th>009</th>\n",
              "      <th>010</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>macro avg</th>\n",
              "      <th>weighted avg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>precision</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.9</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.727273</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.727273</td>\n",
              "      <td>0.636364</td>\n",
              "      <td>0.785714</td>\n",
              "      <td>0.824805</td>\n",
              "      <td>0.809400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>recall</th>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>0.888889</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.888889</td>\n",
              "      <td>0.777778</td>\n",
              "      <td>0.785714</td>\n",
              "      <td>0.786111</td>\n",
              "      <td>0.785714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f1-score</th>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.526316</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.705882</td>\n",
              "      <td>0.947368</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>0.785714</td>\n",
              "      <td>0.790338</td>\n",
              "      <td>0.784275</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>support</th>\n",
              "      <td>8.000000</td>\n",
              "      <td>10.0</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>5.0</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>0.785714</td>\n",
              "      <td>84.000000</td>\n",
              "      <td>84.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d823878e-38ce-4cea-9555-98a372be2f33')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d823878e-38ce-4cea-9555-98a372be2f33 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d823878e-38ce-4cea-9555-98a372be2f33');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-baac741b-14d6-4827-b947-3e5cef859956\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-baac741b-14d6-4827-b947-3e5cef859956')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-baac741b-14d6-4827-b947-3e5cef859956 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"show_confusion(best_title_cnn)\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"001\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.566946592422892,\n        \"min\": 0.75,\n        \"max\": 8.0,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.75,\n          8.0,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"002\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.55,\n        \"min\": 0.9,\n        \"max\": 10.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          10.0,\n          0.9\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"003\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.647063362378099,\n        \"min\": 0.5,\n        \"max\": 6.0,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.5,\n          6.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"004\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.236415544414492,\n        \"min\": 0.5,\n        \"max\": 9.0,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.5555555555555556,\n          9.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"005\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.097839372362155,\n        \"min\": 0.7272727272727273,\n        \"max\": 9.0,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.8888888888888888,\n          9.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"006\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.640695644996192,\n        \"min\": 0.6,\n        \"max\": 10.0,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.6,\n          10.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"007\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.02564579908901,\n        \"min\": 0.9,\n        \"max\": 9.0,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          1.0,\n          9.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"008\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.0,\n        \"min\": 1.0,\n        \"max\": 5.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          5.0,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"009\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.097839372362155,\n        \"min\": 0.7272727272727273,\n        \"max\": 9.0,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.8888888888888888,\n          9.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"010\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.148046211005352,\n        \"min\": 0.6363636363636364,\n        \"max\": 9.0,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.7777777777777778,\n          9.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.7857142857142857,\n        \"max\": 0.7857142857142857,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.7857142857142857\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"macro avg\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 41.599794624166364,\n        \"min\": 0.7861111111111112,\n        \"max\": 84.0,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.7861111111111112\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"weighted avg\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 41.603436645139034,\n        \"min\": 0.7842752890629937,\n        \"max\": 84.0,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.7857142857142857\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Matriz de confusión (cruda): outputs/SimpleCNN_confusion_matrix.csv\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "          pred_001  pred_002  pred_003  pred_004  pred_005  pred_006  \\\n",
              "true_001         6         0         0         0         0         0   \n",
              "true_002         0         9         0         0         0         0   \n",
              "true_003         0         0         3         0         1         0   \n",
              "true_004         0         1         0         5         1         0   \n",
              "true_005         0         0         0         1         8         0   \n",
              "true_006         0         0         0         3         0         6   \n",
              "true_007         0         0         0         0         0         0   \n",
              "true_008         0         0         0         0         0         0   \n",
              "true_009         0         0         0         0         0         1   \n",
              "true_010         0         0         0         1         1         0   \n",
              "\n",
              "          pred_007  pred_008  pred_009  pred_010  \n",
              "true_001         0         0         0         2  \n",
              "true_002         0         0         0         1  \n",
              "true_003         0         0         2         0  \n",
              "true_004         1         0         0         1  \n",
              "true_005         0         0         0         0  \n",
              "true_006         0         0         1         0  \n",
              "true_007         9         0         0         0  \n",
              "true_008         0         5         0         0  \n",
              "true_009         0         0         8         0  \n",
              "true_010         0         0         0         7  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ab5e0e70-067f-428a-9f8f-a3efdaac8ea9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pred_001</th>\n",
              "      <th>pred_002</th>\n",
              "      <th>pred_003</th>\n",
              "      <th>pred_004</th>\n",
              "      <th>pred_005</th>\n",
              "      <th>pred_006</th>\n",
              "      <th>pred_007</th>\n",
              "      <th>pred_008</th>\n",
              "      <th>pred_009</th>\n",
              "      <th>pred_010</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>true_001</th>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>true_002</th>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>true_003</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>true_004</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>true_005</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>true_006</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>true_007</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>true_008</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>true_009</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>true_010</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ab5e0e70-067f-428a-9f8f-a3efdaac8ea9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ab5e0e70-067f-428a-9f8f-a3efdaac8ea9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ab5e0e70-067f-428a-9f8f-a3efdaac8ea9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-c770bde9-b247-40a5-94b1-3a1151dec6df\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c770bde9-b247-40a5-94b1-3a1151dec6df')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-c770bde9-b247-40a5-94b1-3a1151dec6df button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"show_confusion(best_title_cnn)\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"pred_001\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 6,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_002\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 0,\n        \"max\": 9,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          9\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_003\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 3,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          3,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_004\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 5,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          5,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_005\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 0,\n        \"max\": 8,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_006\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 6,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_007\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 0,\n        \"max\": 9,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_008\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 5,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          5,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_009\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 0,\n        \"max\": 8,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          2,\n          8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_010\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 0,\n        \"max\": 7,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          1,\n          7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Matriz de confusión (normalizada por fila): outputs/SimpleCNN_confusion_matrix_norm.csv\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "          pred_001  pred_002  pred_003  pred_004  pred_005  pred_006  \\\n",
              "true_001      0.75  0.000000       0.0  0.000000  0.000000  0.000000   \n",
              "true_002      0.00  0.900000       0.0  0.000000  0.000000  0.000000   \n",
              "true_003      0.00  0.000000       0.5  0.000000  0.166667  0.000000   \n",
              "true_004      0.00  0.111111       0.0  0.555556  0.111111  0.000000   \n",
              "true_005      0.00  0.000000       0.0  0.111111  0.888889  0.000000   \n",
              "true_006      0.00  0.000000       0.0  0.300000  0.000000  0.600000   \n",
              "true_007      0.00  0.000000       0.0  0.000000  0.000000  0.000000   \n",
              "true_008      0.00  0.000000       0.0  0.000000  0.000000  0.000000   \n",
              "true_009      0.00  0.000000       0.0  0.000000  0.000000  0.111111   \n",
              "true_010      0.00  0.000000       0.0  0.111111  0.111111  0.000000   \n",
              "\n",
              "          pred_007  pred_008  pred_009  pred_010  \n",
              "true_001  0.000000       0.0  0.000000  0.250000  \n",
              "true_002  0.000000       0.0  0.000000  0.100000  \n",
              "true_003  0.000000       0.0  0.333333  0.000000  \n",
              "true_004  0.111111       0.0  0.000000  0.111111  \n",
              "true_005  0.000000       0.0  0.000000  0.000000  \n",
              "true_006  0.000000       0.0  0.100000  0.000000  \n",
              "true_007  1.000000       0.0  0.000000  0.000000  \n",
              "true_008  0.000000       1.0  0.000000  0.000000  \n",
              "true_009  0.000000       0.0  0.888889  0.000000  \n",
              "true_010  0.000000       0.0  0.000000  0.777778  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7a9e6a20-4d69-4636-97fa-872a9ef31cf5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pred_001</th>\n",
              "      <th>pred_002</th>\n",
              "      <th>pred_003</th>\n",
              "      <th>pred_004</th>\n",
              "      <th>pred_005</th>\n",
              "      <th>pred_006</th>\n",
              "      <th>pred_007</th>\n",
              "      <th>pred_008</th>\n",
              "      <th>pred_009</th>\n",
              "      <th>pred_010</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>true_001</th>\n",
              "      <td>0.75</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>true_002</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.100000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>true_003</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>true_004</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.111111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>true_005</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.888889</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>true_006</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>true_007</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>true_008</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>true_009</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.888889</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>true_010</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.777778</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7a9e6a20-4d69-4636-97fa-872a9ef31cf5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7a9e6a20-4d69-4636-97fa-872a9ef31cf5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7a9e6a20-4d69-4636-97fa-872a9ef31cf5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-750f93a3-1636-48a6-ab3f-4b9d8fe98360\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-750f93a3-1636-48a6-ab3f-4b9d8fe98360')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-750f93a3-1636-48a6-ab3f-4b9d8fe98360 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"show_confusion(best_title_cnn)\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"pred_001\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.23717082451262844,\n        \"min\": 0.0,\n        \"max\": 0.75,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0,\n          0.75\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_002\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.282864535479618,\n        \"min\": 0.0,\n        \"max\": 0.9,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.0,\n          0.9\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_003\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.15811388300841897,\n        \"min\": 0.0,\n        \"max\": 0.5,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.5,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_004\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1847440379581075,\n        \"min\": 0.0,\n        \"max\": 0.555556,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.555556,\n          0.3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_005\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2747364778036502,\n        \"min\": 0.0,\n        \"max\": 0.888889,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.166667,\n          0.888889\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_006\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.18908486304329072,\n        \"min\": 0.0,\n        \"max\": 0.6,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.0,\n          0.6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_007\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3142696805273564,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.0,\n          0.111111\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_008\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.31622776601683794,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_009\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2860472846462821,\n        \"min\": 0.0,\n        \"max\": 0.888889,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.333333,\n          0.888889\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_010\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2441082811133207,\n        \"min\": 0.0,\n        \"max\": 0.777778,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.1,\n          0.777778\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    }
  ]
}