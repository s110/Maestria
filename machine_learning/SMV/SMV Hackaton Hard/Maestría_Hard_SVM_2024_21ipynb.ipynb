{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/s110/CollabNotebooks/blob/main/Maestria/MachineLearning/Maestr%C3%ADa_Hard_SVM_2024_21ipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    " # Practice  Hard SVM.\n",
    " ----\n",
    "  \n",
    "  University : UTEC \\\\\n",
    "  Course       : Machine Learning \\\\\n",
    "  Professor    : Cristian López Del Alamo \\\\\n",
    "  Topic        : Hard SVM \\\\\n",
    "  Termina      : 12:45\n",
    "   \n",
    "\n",
    " ----\n",
    "\n",
    "Write the names and surnames of the members and the percentage of participation of each one in the development of the practice:\n",
    " - Integrante 1: (%)\n",
    " - Integrante 2: (%)\n",
    " - Integrante 3: (%)\n",
    " - Integrante 4: (%)\n",
    "\n",
    "\n",
    " ----\n",
    "\n",
    "\n",
    "  \n",
    "\n"
   ],
   "metadata": {
    "id": "h5URl9pFHUec"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Loading libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import cvxopt\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics"
   ],
   "metadata": {
    "id": "sit2AQ1GZDju",
    "ExecuteTime": {
     "end_time": "2025-06-04T03:59:17.311970Z",
     "start_time": "2025-06-04T03:59:17.307798Z"
    }
   },
   "outputs": [],
   "execution_count": 32
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Lagrange Multipliers\n",
    "\n",
    "$\\frac{\\partial f(x)}{ \\partial x} = λ \\frac{\\partial g(  x)}{ \\partial x}$\n",
    "\n",
    "----\n",
    "Find the values of  $λ_i$ for each training elements $X_i$.\n",
    "\n",
    "The  ***GetLambda*** function returns a vector that we will call  lambda, such that   $lambda[i]$ will be  $0$, if the element  $X[i]$ does not intersect with any of the lines   $XW^t + b >=1$ o $XW^t + b >=0$\n",
    "\n",
    "Note: X is a matrix, so $X_i$ will be a  $K$-dimensional vector that represent the  i-th  object or  $k$-dimensional point, and  $X_{ij}$ is  the  j-th  element of the  i-th objet.\n",
    "\n",
    "----\n",
    "\n",
    "\n",
    "- **Note: The code for finding the lambda values is provided to you.**"
   ],
   "metadata": {
    "id": "_-o70Lb1qRVv"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from cvxopt import matrix, solvers\n",
    "\n",
    "def GetLambda(X, y):\n",
    "    n, m = X.shape\n",
    "    y = y.astype(float)\n",
    "    y_col = y.reshape(-1, 1)\n",
    "    K = np.dot(X, X.T) * np.dot(y_col, y_col.T)  # Kernel\n",
    "    P = matrix(K)\n",
    "    q = matrix(-np.ones(n))\n",
    "    G = matrix(-np.eye(n))\n",
    "    h = matrix(np.zeros(n))\n",
    "    A = matrix(y.reshape(1, -1))\n",
    "    b = matrix(np.zeros(1))\n",
    "    sol = solvers.qp(P, q, G, h, A, b)\n",
    "    alpha = np.array(sol['x'])\n",
    "    return alpha\n",
    "\n",
    "#Ejemplo para utilizar esta función\n",
    "#lamda = GetLambda(X,Y)\n",
    "#sv = lamda > 1e-5\n",
    "#print(sv)"
   ],
   "metadata": {
    "id": "vI6Hn-6UUV1I",
    "ExecuteTime": {
     "end_time": "2025-06-04T05:10:39.695968Z",
     "start_time": "2025-06-04T05:10:39.690214Z"
    }
   },
   "outputs": [],
   "execution_count": 46
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2 Calculation of the Weights W\n",
    "$W_j = \\sum_{i=0}^n \\lambda_iy_ix_{ij}$  \n",
    "\n",
    "----\n",
    "Where: $λ_i$ represent  $i-th$ lagrange multiplier, $W_j$ is the $j-th$ weight,   $x_{ij}$ denotes the value of feacture $(j)$ for the $(i)-th$ training objetc, and $y_i$ is the expected output (1 or -1) for the $i-th$ object.\n",
    "\n",
    "$W_j = \\sum_{i=0}^n \\lambda_iy_ix_{ij}$  \n",
    "Note that the summation only includes elements for which the Lagrange\n",
    "\n",
    "----\n",
    "\n",
    "multiplier $lamnda_i$ is nonzero.\n",
    "\n"
   ],
   "metadata": {
    "id": "Lbvs2lvNlmNa"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "def Get_W(X, Y, lambda_list):\n",
    "  \"\"\"\n",
    "  Calcula el vector de pesos W para un SVM lineal.\n",
    "\n",
    "  Args:\n",
    "    X (np.ndarray): Matriz de datos de entrenamiento, donde cada fila es una\n",
    "                    muestra y cada columna es una característica.\n",
    "                    Dimensiones: (n_samples, n_features).\n",
    "    Y (np.ndarray): Vector de etiquetas de clase (1 o -1) para cada muestra.\n",
    "                    Dimensiones: (n_samples,) o (n_samples, 1).\n",
    "    lambda_list (np.ndarray): Vector de multiplicadores de Lagrange.\n",
    "                              Dimensiones: (n_samples,) o (n_samples, 1).\n",
    "\n",
    "  Returns:\n",
    "    np.ndarray: El vector de pesos W. Dimensiones: (n_features,).\n",
    "  \"\"\"\n",
    "  # Asegurarse de que lambda_list y Y sean arrays 1D para cálculos consistentes.\n",
    "  # La salida de GetLambda (sol['x']) es una matriz cvxopt, luego convertida a np.array,\n",
    "  # que probablemente tiene forma (n_samples, 1). Usamos flatten().\n",
    "  # Y también podría ser (n_samples,) o (n_samples, 1).\n",
    "  lambda_flat = lambda_list.flatten()\n",
    "  Y_flat = Y.flatten()\n",
    "\n",
    "  # n_samples, n_features = X.shape # No es estrictamente necesario aquí\n",
    "\n",
    "  # La fórmula es W_j = sum_i (lambda_i * y_i * x_ij)\n",
    "  # Esto se puede vectorizar como W = X^T @ (lambda * y)\n",
    "\n",
    "  # 1. Calcular el término (lambda_i * y_i) para cada muestra.\n",
    "  # Este término pondera la contribución de cada muestra.\n",
    "  # Si lambda_i es cercano a 0 (vector no de soporte), su contribución es mínima.\n",
    "  weighted_terms = lambda_flat * Y_flat\n",
    "\n",
    "  # 2. Calcular W.\n",
    "  # W_j = sum_i (weighted_terms_i * X_ij)\n",
    "  # Esto es equivalente a la transpuesta de X multiplicada por los términos ponderados.\n",
    "  # X.T tiene dimensiones (n_features, n_samples)\n",
    "  # weighted_terms tiene dimensiones (n_samples,)\n",
    "  # El resultado W tendrá dimensiones (n_features,)\n",
    "  W = np.dot(X.T, weighted_terms)\n",
    "\n",
    "  return W"
   ],
   "metadata": {
    "id": "xJwm8DaClJ-f",
    "ExecuteTime": {
     "end_time": "2025-06-04T03:59:17.355711Z",
     "start_time": "2025-06-04T03:59:17.352312Z"
    }
   },
   "outputs": [],
   "execution_count": 34
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Finding the Bias (b)\n",
    "\n",
    "$XW^t + b = 0$\n",
    "\n",
    "$b = - \\frac{1}{n}∑_{i=0}^n X_iW^t$\n",
    "\n",
    "Where $X_i$ is a $k$-dimensional vector representing the $i$-th object, and $k$ is the number of features of the object.\n",
    "\n"
   ],
   "metadata": {
    "id": "wctPuU-jnU0Q"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def Get_b(X, W):\n",
    "  \"\"\"\n",
    "  Calcula el término de sesgo b para un SVM lineal usando la fórmula\n",
    "  b = - (1/n) * sum(X_i @ W).\n",
    "\n",
    "  Args:\n",
    "    X (np.ndarray): Matriz de datos de entrenamiento, donde cada fila es una\n",
    "                    muestra y cada columna es una característica.\n",
    "                    Dimensiones: (n_samples, n_features).\n",
    "    W (np.ndarray): Vector de pesos W. Asumimos que es un array 1D.\n",
    "                    Dimensiones: (n_features,).\n",
    "\n",
    "  Returns:\n",
    "    float: El término de sesgo b.\n",
    "  \"\"\"\n",
    "  # n_samples es el número de filas en X\n",
    "  n_samples = X.shape[0]\n",
    "\n",
    "  # W es un vector 1D (n_features,).\n",
    "  # X es una matriz (n_samples, n_features).\n",
    "  # np.dot(X, W) calcula el producto punto de cada fila de X con W.\n",
    "  # El resultado es un array 1D de longitud n_samples, donde cada\n",
    "  # elemento es X_i @ W^T (o X_i · W).\n",
    "  # Ejemplo:\n",
    "  # X = [[x11, x12], [x21, x22]]\n",
    "  # W = [w1, w2]\n",
    "  # np.dot(X, W) = [x11*w1 + x12*w2, x21*w1 + x22*w2]\n",
    "  xw_products = np.dot(X, W)\n",
    "\n",
    "  # Sumamos todos estos productos punto\n",
    "  sum_xw_products = np.sum(xw_products)\n",
    "\n",
    "  # Calculamos el promedio de los productos punto\n",
    "  mean_xw_products = sum_xw_products / n_samples\n",
    "\n",
    "  # b es el negativo de este promedio\n",
    "  b = -mean_xw_products\n",
    "\n",
    "  return b"
   ],
   "metadata": {
    "id": "IujB29jtnUl7",
    "ExecuteTime": {
     "end_time": "2025-06-04T03:59:17.388314Z",
     "start_time": "2025-06-04T03:59:17.383869Z"
    }
   },
   "outputs": [],
   "execution_count": 35
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Testing Stage\n",
    "\n",
    "----\n",
    "For this stage, one should only calculate :\n",
    "\n",
    "- $f(X_j) = X_jW^t + b$\n",
    "\n",
    "But since we have already calculated the values of the parameters $W$ and  $b$, then by substituting we have :\n",
    "\n",
    "- $f(X_j) = \\sum_{i=0}^n \\lambda_iy_i<X_{i},X_{j}> + b$\n",
    "\n",
    "Donde: $X_i$ is the i-th  training vector and  $X_j$   is the new vector that passes through the model for predicting the class (1 or -1)\n",
    "\n",
    "Finally, to determine which class the new vector $X_j$   belongs to, it is sufficient to check the sign of f(X_j).\n",
    "\n",
    "  - **If $f(X_j) >=0$ then $Y_j$ = 1 else $Y_j = -1$**\n",
    "  -----"
   ],
   "metadata": {
    "id": "k7L3GAtNoUo7"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def Test(X_new, W, b):\n",
    "  \"\"\"\n",
    "  Predice las etiquetas de clase para nuevas muestras utilizando un modelo SVM lineal\n",
    "  previamente entrenado (con W y b conocidos).\n",
    "\n",
    "  Args:\n",
    "    X_new (np.ndarray): Matriz de nuevas muestras a clasificar.\n",
    "                        Cada fila es una muestra, cada columna es una característica.\n",
    "                        Dimensiones: (n_new_samples, n_features).\n",
    "    W (np.ndarray): Vector de pesos del SVM.\n",
    "                    Asumimos que es un array 1D.\n",
    "                    Dimensiones: (n_features,).\n",
    "    b (float): Término de sesgo del SVM.\n",
    "\n",
    "  Returns:\n",
    "    np.ndarray: Un vector de etiquetas de clase predichas (1 o -1)\n",
    "                para cada muestra en X_new.\n",
    "                Dimensiones: (n_new_samples,).\n",
    "  \"\"\"\n",
    "  # Calcular la función de decisión para cada muestra en X_new:\n",
    "  # f(X_j) = X_j @ W + b\n",
    "  # np.dot(X_new, W) calcula el producto punto de cada fila de X_new con W.\n",
    "  # Si X_new es (m, k) y W es (k,), el resultado es (m,).\n",
    "  decision_scores = np.dot(X_new, W) + b\n",
    "\n",
    "  # Aplicar la regla de clasificación:\n",
    "  # Si f(X_j) >= 0, entonces Y_j = 1\n",
    "  # Si f(X_j) < 0, entonces Y_j = -1\n",
    "  # La función np.where es ideal para esto.\n",
    "  predictions = np.where(decision_scores >= 0, 1, -1)\n",
    "\n",
    "  return predictions"
   ],
   "metadata": {
    "id": "froBqp3Mp9C5",
    "ExecuteTime": {
     "end_time": "2025-06-04T03:59:17.408171Z",
     "start_time": "2025-06-04T03:59:17.405037Z"
    }
   },
   "outputs": [],
   "execution_count": 36
  },
  {
   "cell_type": "markdown",
   "source": [
    "Database for Testing:\n",
    "[Download](https://docs.google.com/spreadsheets/d/15-E3kiLJ6bCyXuJvSmxYAp2QYMkPX2QlQ597fAsPYy8/edit#gid=0).\n",
    "\n",
    "----\n",
    "Download the database to your disk and use files.upload() to load it onto the drive. The code is provided.\n",
    "----\n",
    "\n",
    "\n",
    "- Split the dataset into 70% for training and 30% for testing.\n",
    "- Add a value of 1 for the first class and -1 for the second class.\n",
    "- In the testing stage, find the number of elements correctly classified and the number of elements incorrectly classified for each class\n",
    "\n",
    "- Create a [confusion matrix](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html) which will show us the efficiency of the method.\n",
    "\n",
    "- Do not forget to normalize the data.\n",
    "\n",
    "- Plot the lines that separate both classes.\n",
    "\n",
    "----\n"
   ],
   "metadata": {
    "id": "LslGSJAprlPm"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# code for loading  the Dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "url='https://github.com/s110/CollabNotebooks/raw/refs/heads/main/Maestria/MachineLearning/SMV/DataSet_Iris_2_Clases.csv'\n",
    "\n",
    "data = pd.read_csv(url,sep=';')\n",
    "\n",
    "X_df = data[[\"sepal.length\",\"sepal.width\",\"petal.length\",\"petal.width\"]]\n",
    "Y_df = data[[\"variety\"]]\n",
    "print(X_df)\n",
    "\n",
    "# Splitting the dataset into training and testing\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# --- 1. Conversión de Etiquetas ---\n",
    "# Identificar las clases únicas\n",
    "unique_classes = Y_df['variety'].unique()\n",
    "if len(unique_classes) != 2:\n",
    "    raise ValueError(\"Se esperan exactamente dos clases para este SVM binario.\")\n",
    "\n",
    "# Mapear la primera clase a 1 y la segunda a -1\n",
    "class_mapping = {unique_classes[0]: 1, unique_classes[1]: -1}\n",
    "Y_numeric = Y_df['variety'].map(class_mapping).values # .values para obtener un array NumPy\n",
    "\n",
    "# --- División del Dataset ---\n",
    "# (Ya lo tenías, solo asegurándonos de usar Y_numeric)\n",
    "X_train_df, X_test_df, Y_train, Y_test = train_test_split(\n",
    "    X_df, Y_numeric, random_state=104, test_size=0.30, shuffle=True\n",
    ")\n",
    "\n",
    "# Convertir DataFrames de X a arrays NumPy para las funciones SVM\n",
    "X_train = X_train_df.values\n",
    "X_test = X_test_df.values\n",
    "\n",
    "print(\"Forma de X_train:\", X_train.shape)\n",
    "print(\"Forma de Y_train:\", Y_train.shape)\n",
    "print(\"Forma de X_test:\", X_test.shape)\n",
    "print(\"Forma de Y_test:\", Y_test.shape)\n",
    "print(\"Clases únicas en Y_train:\", np.unique(Y_train))\n",
    "print(\"Clases únicas en Y_test:\", np.unique(Y_test))"
   ],
   "metadata": {
    "id": "iwAZ6rT9Wq2R",
    "ExecuteTime": {
     "end_time": "2025-06-04T05:13:52.011339Z",
     "start_time": "2025-06-04T05:13:51.433896Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    sepal.length  sepal.width  petal.length  petal.width\n",
      "0            5.1          3.5           1.4          0.2\n",
      "1            4.9          3.0           1.4          0.2\n",
      "2            4.7          3.2           1.3          0.2\n",
      "3            4.6          3.1           1.5          0.2\n",
      "4            5.0          3.6           1.4          0.2\n",
      "..           ...          ...           ...          ...\n",
      "95           5.7          3.0           4.2          1.2\n",
      "96           5.7          2.9           4.2          1.3\n",
      "97           6.2          2.9           4.3          1.3\n",
      "98           5.1          2.5           3.0          1.1\n",
      "99           5.7          2.8           4.1          1.3\n",
      "\n",
      "[100 rows x 4 columns]\n",
      "Forma de X_train: (70, 4)\n",
      "Forma de Y_train: (70,)\n",
      "Forma de X_test: (30, 4)\n",
      "Forma de Y_test: (30,)\n",
      "Clases únicas en Y_train: [-1  1]\n",
      "Clases únicas en Y_test: [-1  1]\n"
     ]
    }
   ],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T05:25:14.601634Z",
     "start_time": "2025-06-04T05:25:14.488873Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# --- 2. Normalización de Características ---\n",
    "scaler = StandardScaler()\n",
    "X_train_normalized = scaler.fit_transform(X_train)\n",
    "X_test_normalized = scaler.transform(X_test) # Usar el mismo scaler ajustado en train\n",
    "\n",
    "print(\"\\nPrimeras 2 filas de X_train normalizado:\\n\", X_train_normalized[:2])\n",
    "print(\"Media de X_train_normalized (debería ser cercana a 0):\", np.mean(X_train_normalized, axis=0))\n",
    "print(\"Std de X_train_normalized (debería ser cercana a 1):\", np.std(X_train_normalized, axis=0))\n",
    "\n",
    "# --- 3. Entrenamiento del Modelo SVM ---\n",
    "print(\"\\nEntrenando el modelo SVM...\")\n",
    "# Asegurarse de que Y_train sea un vector columna para GetLambda si es necesario\n",
    "# o ajustar GetLambda para que maneje Y 1D correctamente.\n",
    "# La implementación actual de GetLambda espera y.reshape(1,-1) para A,\n",
    "# y y.astype(float) para el cálculo de K. Y_train ya es 1D.\n",
    "lambda_values = GetLambda(X_train_normalized, Y_train)\n",
    "print(\"Forma de lambda_values:\", lambda_values.shape)\n",
    "\n",
    "W_vector = Get_W(X_train_normalized, Y_train, lambda_values)\n",
    "print(\"Vector de pesos W:\", W_vector)\n",
    "print(\"Forma de W_vector:\", W_vector.shape)\n",
    "\n",
    "# Para Get_b, la fórmula que usamos es b = - (1/n) * sum(X_i @ W)\n",
    "# Alternativamente, b se puede calcular usando vectores de soporte.\n",
    "# b_offset = Get_b(X_train_normalized, W_vector)\n",
    "\n",
    "# Cálculo de b usando vectores de soporte (más robusto para SVM)\n",
    "# Identificar vectores de soporte (aquellos con lambda > umbral pequeño)\n",
    "support_vector_indices = np.where(lambda_values.flatten() > 1e-5)[0]\n",
    "if len(support_vector_indices) == 0:\n",
    "    print(\"Advertencia: No se encontraron vectores de soporte. El modelo puede no haber convergido bien.\")\n",
    "    # Fallback a la media si no hay SVs (aunque esto es inusual)\n",
    "    b_offset = Get_b(X_train_normalized, W_vector)\n",
    "else:\n",
    "    # Calcular b para cada vector de soporte y promediar\n",
    "    # b = y_s - X_s @ W\n",
    "    b_values_sv = Y_train[support_vector_indices] - np.dot(X_train_normalized[support_vector_indices], W_vector)\n",
    "    b_offset = np.mean(b_values_sv)\n",
    "\n",
    "print(\"Término de sesgo b:\", b_offset)\n",
    "\n",
    "\n",
    "# --- 4. Prueba del Modelo ---\n",
    "print(\"\\nProbando el modelo...\")\n",
    "Y_pred = Test(X_test_normalized, W_vector, b_offset)\n",
    "print(\"Predicciones (primeros 10):\", Y_pred[:10])\n",
    "print(\"Valores reales (primeros 10):\", Y_test[:10])\n",
    "\n",
    "# --- 5. Evaluación del Modelo ---\n",
    "print(\"\\nEvaluación del modelo:\")\n",
    "correct_predictions = np.sum(Y_pred == Y_test)\n",
    "total_predictions = len(Y_test)\n",
    "accuracy = correct_predictions / total_predictions\n",
    "print(f\"Precisión (Accuracy): {accuracy:.4f}\")\n",
    "\n",
    "# Elementos correctamente e incorrectamente clasificados por clase\n",
    "for cls_val in np.unique(Y_test):\n",
    "    cls_mask_test = (Y_test == cls_val)\n",
    "    cls_mask_pred = (Y_pred == cls_val)\n",
    "\n",
    "    correctly_classified = np.sum(cls_mask_test & cls_mask_pred)\n",
    "    # Incorrectamente clasificados para esta clase verdadera:\n",
    "    # Son aquellos donde Y_test es cls_val PERO Y_pred NO es cls_val\n",
    "    incorrectly_classified = np.sum(cls_mask_test & ~cls_mask_pred)\n",
    "\n",
    "    print(f\"Clase {int(cls_val)}:\")\n",
    "    print(f\"  Correctamente clasificados: {correctly_classified}\")\n",
    "    print(f\"  Incorrectamente clasificados: {incorrectly_classified}\")\n",
    "\n",
    "# Matriz de Confusión\n",
    "cm = metrics.confusion_matrix(Y_test, Y_pred)\n",
    "print(\"\\nMatriz de Confusión:\")\n",
    "print(cm)\n",
    "\n",
    "# Para una mejor visualización de la matriz de confusión\n",
    "import seaborn as sns # Opcional, para una gráfica más bonita\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=class_mapping.keys(), # O [1, -1] si prefieres\n",
    "            yticklabels=class_mapping.keys()) # O [1, -1] si prefieres\n",
    "plt.xlabel('Predicción')\n",
    "plt.ylabel('Valor Real')\n",
    "plt.title('Matriz de Confusión')\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Primeras 2 filas de X_train normalizado:\n",
      " [[ 1.03971245 -0.17508023  1.20363017  1.0967791 ]\n",
      " [-0.52208737  1.38472548 -0.95138424 -0.6763049 ]]\n",
      "Media de X_train_normalized (debería ser cercana a 0): [-1.18952467e-15 -3.71131697e-16  1.15780401e-16  1.04678171e-16]\n",
      "Std de X_train_normalized (debería ser cercana a 1): [1. 1. 1. 1.]\n",
      "\n",
      "Entrenando el modelo SVM...\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -2.1816e+00 -3.6160e+00  1e+02  1e+01  1e+00\n",
      " 1: -5.2604e-01 -1.3391e+00  1e+01  8e-01  1e-01\n",
      " 2: -1.1901e-01 -8.9195e-01  8e-01  2e-16  6e-16\n",
      " 3: -3.4787e-01 -5.7000e-01  2e-01  9e-17  4e-16\n",
      " 4: -4.8540e-01 -5.3575e-01  5e-02  6e-17  3e-16\n",
      " 5: -5.1148e-01 -5.3353e-01  2e-02  2e-16  3e-16\n",
      " 6: -5.2747e-01 -5.2909e-01  2e-03  2e-16  4e-16\n",
      " 7: -5.2876e-01 -5.2881e-01  5e-05  1e-16  5e-16\n",
      " 8: -5.2880e-01 -5.2880e-01  5e-07  2e-16  5e-16\n",
      "Optimal solution found.\n",
      "Forma de lambda_values: (70, 1)\n",
      "Vector de pesos W: [-0.32641071  0.27152156 -0.71457847 -0.60556692]\n",
      "Forma de W_vector: (4,)\n",
      "Término de sesgo b: -0.30133802472563265\n",
      "\n",
      "Probando el modelo...\n",
      "Predicciones (primeros 10): [ 1  1  1  1 -1 -1 -1 -1 -1 -1]\n",
      "Valores reales (primeros 10): [ 1  1  1  1 -1 -1 -1 -1 -1 -1]\n",
      "\n",
      "Evaluación del modelo:\n",
      "Precisión (Accuracy): 1.0000\n",
      "Clase -1:\n",
      "  Correctamente clasificados: 15\n",
      "  Incorrectamente clasificados: 0\n",
      "Clase 1:\n",
      "  Correctamente clasificados: 15\n",
      "  Incorrectamente clasificados: 0\n",
      "\n",
      "Matriz de Confusión:\n",
      "[[15  0]\n",
      " [ 0 15]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 600x400 with 2 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 61
  },
  {
   "metadata": {
    "id": "dGQYlGzEX8u6"
   },
   "cell_type": "markdown",
   "source": [
    "----\n",
    "\n",
    "- Subir el link de su colab a canvas\n",
    "- Disfruten aprendiendo. La única forma de aprender es haciendo.\n",
    "- Buena Suerte.\n",
    "----"
   ]
  }
 ]
}
